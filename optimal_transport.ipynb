{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import TransformerClassifier\n",
    "from dataloader import *\n",
    "import torch\n",
    "import ot\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "tokenizer = Tokenizer()\n",
    "loader = DataLoader(tokenize = tokenizer.tokenize)\n",
    "\n",
    "# import data (combine train/test as we split afterwards anyways)\n",
    "data = pd.concat([pd.read_csv(\"./Data/SMS_train.csv\", encoding='ISO-8859-1'),\n",
    "                  pd.read_csv(\"./Data/SMS_test.csv\", encoding='ISO-8859-1')])\n",
    "\n",
    "# convert string label to binary (int) label (spam:1, non-spam:0)\n",
    "labels = pd.Series((data['Label'] == 'Spam').astype(int))\n",
    "data['Label'] = labels\n",
    "\n",
    "# train, test, val split\n",
    "train, valid, test = loader.make_dataset(data[['Message_body', 'Label']])\n",
    "vocab = loader.get_vocab(train.iloc[:, 0])\n",
    "train_iter, valid_iter, test_iter = loader.make_iter(train, valid, test,\n",
    "                                                     batch_size=128,\n",
    "                                                     device=device)\n",
    "\n",
    "# NLP stuff\n",
    "pad_idx = vocab['__PAD__']\n",
    "voc_size = len(vocab)\n",
    "print(\"Vocabulary Size : \", voc_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelA = TransformerClassifier(src_pad_idx = pad_idx,\n",
    "                              enc_voc_size = voc_size,\n",
    "                              max_len = 256,\n",
    "                              d_model = 512,\n",
    "                              ffn_hidden = 2048,\n",
    "                              n_head = 1,\n",
    "                              n_layers = 1,\n",
    "                              drop_prob = 0.1,\n",
    "                              device = device)\n",
    "\n",
    "modelA.load_state_dict(torch.load(\"Models\\modelA\"))\n",
    "modelA.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelB = TransformerClassifier(src_pad_idx = pad_idx,\n",
    "                              enc_voc_size = voc_size,\n",
    "                              max_len = 256,\n",
    "                              d_model = 512,\n",
    "                              ffn_hidden = 2048,\n",
    "                              n_head = 1,\n",
    "                              n_layers = 1,\n",
    "                              drop_prob = 0.1,\n",
    "                              device = device)\n",
    "\n",
    "modelB.load_state_dict(torch.load(\"Models\\modelB\"))\n",
    "modelB.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OT Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSupport(model, trainloader, l, alignment = \"acts\", numOfBatches= 10):\n",
    "    '''\n",
    "    Get the support matrices using Activation-based (\"acts\") or Weight-based (\"wts\") alignment \n",
    "    '''\n",
    "    if alignment == \"acts\":\n",
    "        activation = None\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            if i >= numOfBatches:\n",
    "                break\n",
    "            \n",
    "            inputs, targets = data\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            if activation is None:\n",
    "                activation = model.actMatrix[l]\n",
    "            else:\n",
    "                activation = torch.cat((activation, model.actMatrix[l]))\n",
    "\n",
    "        return activation\n",
    "    elif alignment == \"wts\":\n",
    "        return model.state_dict()[l]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusion(nameA, nameB, weightA, weightB, transport_matrix, beta):\n",
    "    support_y = getSupport(modelB, train_iter, nameB, alignment=\"wts\")\n",
    "    # Get the weights at layer \"idx\" from the first model\n",
    "    W_A = weightA\n",
    "    W_B = weightB\n",
    "    # Align the weights from the first model\n",
    "    print(W_A.shape, transport_matrix.shape, torch.diag(1 / beta).shape)\n",
    "    aligned_W = torch.matmul(W_A, torch.matmul(transport_matrix, torch.diag(1 / beta)))\n",
    "    # Get the X-Support\n",
    "    n = W_A.shape[0]\n",
    "    alpha = torch.ones(n) * (1/n)\n",
    "    support_x = getSupport(modelA, train_iter, nameA, alignment=\"wts\")\n",
    "    # Calculate the euclidean distance between the supports\n",
    "    distance = ot.dist(support_x, support_y)\n",
    "    # Calculate beta\n",
    "    m = W_B.shape[0]\n",
    "    beta = torch.ones(m) * (1/m)\n",
    "    # Calculate the transport matrix using optimal transport\n",
    "    print(alpha.shape, beta.shape, distance.shape)\n",
    "    transport_matrix = torch.from_numpy(ot.emd(alpha.numpy(), beta.numpy(), distance.detach().numpy())).float().reshape((n, m))\n",
    "    # Align model neurons\n",
    "    print(torch.diag(1 / beta).shape, transport_matrix.T.shape, aligned_W.shape)\n",
    "    aligned_model = torch.matmul(torch.diag(1 / beta), torch.matmul(transport_matrix.T, aligned_W))\n",
    "    # Get the weights at layer \"idx\" from the second model\n",
    "    fused = (aligned_model + W_B).T / 2 if \"ffn\" in nameA else (aligned_model + W_B) / 2 \n",
    "    return  fused, transport_matrix, beta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fusion via Optimal Transport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusedModel = TransformerClassifier(src_pad_idx = pad_idx,\n",
    "                              enc_voc_size = voc_size,\n",
    "                              max_len = 256,\n",
    "                              d_model = 512,\n",
    "                              ffn_hidden = 2048,\n",
    "                              n_head = 1,\n",
    "                              n_layers = 1,\n",
    "                              drop_prob = 0.1,\n",
    "                              device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the fused weights matrix\n",
    "W_fusion = dict.fromkeys(list(modelA.state_dict().keys()))\n",
    "# Initialize the algorithm\n",
    "m = list(modelB.state_dict().items())[1][1].shape[1]\n",
    "beta = torch.ones(m) * (1/m)\n",
    "transport_matrix = torch.matmul(torch.diag(beta), torch.eye(m))\n",
    "\n",
    "\n",
    "for (nameA, weightA), (nameB, weightB) in zip(modelA.named_parameters(), modelB.named_parameters()):\n",
    "    if nameA == \"encoder.emb.tok_emb.weight\":\n",
    "        W_fusion[nameA] = weightA\n",
    "    else:\n",
    "        if \"weight\" in nameA:\n",
    "            if \"encoder\" in nameA: \n",
    "                W_fusion[nameA], transport_matrix, beta = fusion(nameA, nameB, weightA, weightB, transport_matrix, beta)\n",
    "            else:\n",
    "                W_fusion[nameA] = weightA\n",
    "        elif \"bias\" in nameA:\n",
    "            if \"encoder\" in nameA: \n",
    "                m = weightB.shape[0]\n",
    "                beta_bias = torch.ones(m) * (1/m)\n",
    "                W_A_bias = weightA.reshape(m, 1)\n",
    "                aligned_bias = torch.matmul(torch.diag(1 / beta_bias), torch.matmul(transport_matrix.T, W_A_bias))\n",
    "                W_fusion[nameA] = (aligned_bias + weightB) / 2\n",
    "            else:\n",
    "                W_fusion[nameA] = weightA\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation of the fused model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, iterator, criterion, device):\n",
    "    # set model into evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # validation\n",
    "    # loss, metrics for current epoch\n",
    "    val_epoch_loss = 0\n",
    "    val_epoch_accuracy = 0\n",
    "\n",
    "    with torch.no_grad(): # stop graph\n",
    "        # batches\n",
    "        for i, batch in enumerate(iterator):\n",
    "            src = batch[0] # X\n",
    "            trg = batch[1] # y\n",
    "            src, trg = torch.tensor(src).to(device), torch.tensor(trg).to(device) # put to cpu/gpu\n",
    "            output = model(src)\n",
    "            y_pred = torch.argmax(output, dim=-1) # logits -> labels\n",
    "            output_reshape = output.contiguous().view(-1, output.shape[-1])\n",
    "            trg = trg.to(torch.int64)\n",
    "\n",
    "            loss = criterion(output_reshape, trg) # calculate loss\n",
    "            agreements = torch.eq(y_pred, trg)\n",
    "            accuracy = torch.mean(agreements.double()) # calculate accuracy\n",
    "\n",
    "            val_epoch_loss += loss.item()\n",
    "            val_epoch_accuracy += accuracy\n",
    "\n",
    "    # return mean loss w.r.t. batches\n",
    "    return val_epoch_loss / len(iterator), val_epoch_accuracy / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = validation(fusedModel, valid_iter, criterion, device)\n",
    "print(\"Validation Loss:     \", val_loss)\n",
    "print(\"Validation Accuracy:     \", val_acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in modelA.named_parameters():\n",
    "    print(param[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1744cd9dc0832a8d503a2c77e6bee76d4493b3bf33a738cf38afd0bb2e60262"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

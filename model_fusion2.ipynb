{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchtext.data import Field, BucketIterator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import re\n",
    "from transformers import BertTokenizer\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'cpu'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset initializing start\n",
      "Tokenizing the data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/janoschjungo/Documents/ETH/MSc 3rd semester/Deep Learning/Project/dataloader.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"len\"] = data.iloc[:, 0].apply(lambda x : len(self.tokenize(x)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the data :  29544\n",
      "0\n",
      "review       [[CLS], one, of, the, many, silent, comedies, ...\n",
      "sentiment                                                    0\n",
      "len                                                        186\n",
      "Name: 46539, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23635/23635 [00:00<00:00, 38358.18it/s]\n",
      "100%|██████████| 2954/2954 [00:00<00:00, 35953.82it/s]\n",
      "100%|██████████| 2955/2955 [00:00<00:00, 40028.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset initializing done\n",
      "Vocabulary Size :  23050\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "data = import_data()\n",
    "\n",
    "# train-test-validation split\n",
    "train_iter, valid_iter, test_iter, voc_size, pad_idx = train_test_val_split(data,\n",
    "                                                                            device,\n",
    "                                                                            batch_size=512)\n",
    "\n",
    "# Creating the embedding matrix\n",
    "embedding = torch.nn.Embedding(voc_size, 16)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Training parent models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Idea: We train model A and model B for long enough, s.t. they start overfitting. We use their best models w.r.t. validation set (i.e. not the final model after all training epochs) and fuse them together. The fused model is then trained for long enough as well, saving the best model w.r.t to the same validation set. The fused model is then compared with its parent models on the separate test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "note that dataset is imbalanced -> accuracy is not a good metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# template for training parent models (as we train them the same way)\n",
    "def train_early_stopping(model_name: str, train_iter, valid_iter, epochs, device, lr=2e-4):\n",
    "    # init\n",
    "    model = TransformerClassifier(embedding=embedding,\n",
    "                                  src_pad_idx = pad_idx,\n",
    "                                  enc_voc_size = voc_size,\n",
    "                                  max_len = 256,\n",
    "                                  d_model = 16,\n",
    "                                  ffn_hidden = 32,\n",
    "                                  n_head = 1,\n",
    "                                  n_layers = 1,\n",
    "                                  drop_prob = 0.5,\n",
    "                                  device = device)\n",
    "    model = model.to(device) # put on CPU/GPU\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # train with early stopping\n",
    "    history, best_model, best_model_score = train_save_best(model=model,\n",
    "                                                            iterator=train_iter,\n",
    "                                                            valid_iter=valid_iter,\n",
    "                                                            optimizer=opt,\n",
    "                                                            criterion=loss_fn,\n",
    "                                                            epoch=epochs,\n",
    "                                                            clip=1,\n",
    "                                                            device=device)\n",
    "\n",
    "    # save model\n",
    "    name = f'parallel_training/model{model_name}_IMDB_256'\n",
    "    save_model(model, name=name)\n",
    "\n",
    "    # save history\n",
    "    name = f'parallel_training/history_model{model_name}_IMDB_256'\n",
    "    save_history(history, name=name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "# train parent model A\n",
    "train_early_stopping(model_name='A',\n",
    "                     train_iter=train_iter,\n",
    "                     valid_iter=valid_iter,\n",
    "                     epochs=100,\n",
    "                     device=device,\n",
    "                     lr=2e-4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "# train parent model B\n",
    "train_early_stopping(model_name='B',\n",
    "                     train_iter=train_iter,\n",
    "                     valid_iter=valid_iter,\n",
    "                     epochs=100,\n",
    "                     device=device,\n",
    "                     lr=2e-4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Model fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### (Optional) load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load parent models\n",
    "modelA = TransformerClassifier(src_pad_idx = pad_idx,\n",
    "                               enc_voc_size = voc_size,\n",
    "                               max_len = 256,\n",
    "                               d_model = 512,\n",
    "                               ffn_hidden = 2048,\n",
    "                               n_head = 1,\n",
    "                               n_layers = 1,\n",
    "                               drop_prob = 0.1,\n",
    "                               device = device)\n",
    "modelB = TransformerClassifier(src_pad_idx = pad_idx,\n",
    "                               enc_voc_size = voc_size,\n",
    "                               max_len = 256,\n",
    "                               d_model = 512,\n",
    "                               ffn_hidden = 2048,\n",
    "                               n_head = 1,\n",
    "                               n_layers = 1,\n",
    "                               drop_prob = 0.1,\n",
    "                               device = device)\n",
    "\n",
    "modelA.load_state_dict(torch.load('./Models/modelA'))\n",
    "modelB.load_state_dict(torch.load('./Models/modelB'))\n",
    "\n",
    "modelA = modelA.to(device) # put on CPU/GPU\n",
    "modelB = modelB.to(device) # put on CPU/GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Vanilla fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_fusion = vanilla_fusion(modelA, modelB)\n",
    "model_fusion = model_fusion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Optimal transport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_fusion = TransformerClassifier(src_pad_idx = pad_idx,\n",
    "                                     enc_voc_size = voc_size,\n",
    "                                     max_len = 256,\n",
    "                                     d_model = 512,\n",
    "                                     ffn_hidden = 2048,\n",
    "                                     n_head = 1,\n",
    "                                     n_layers = 1,\n",
    "                                     drop_prob = 0.1,\n",
    "                                     device = device)\n",
    "\n",
    "model_fusion.load_state_dict(torch.load('./Models/model_fusion_OT_pre_retraining'))\n",
    "\n",
    "model_fusion = model_fusion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Test fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Randomly initialiized model for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test with new randomly initialized transformer\n",
    "test_fusion(modelA, modelB, TransformerClassifier(src_pad_idx = pad_idx,\n",
    "                              enc_voc_size = voc_size,\n",
    "                              max_len = 256,\n",
    "                              d_model = 512,\n",
    "                              ffn_hidden = 2048,\n",
    "                              n_head = 1,\n",
    "                              n_layers = 1,\n",
    "                              drop_prob = 0.1,\n",
    "                              device = device).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Fusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test with vanilla fusion\n",
    "test_fusion(modelA, modelB, model_fusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_name = 'model_fusion_OT_post_retraining'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "opt_fusion = torch.optim.SGD(model_fusion.parameters(), lr=0.001)\n",
    "loss_fn_fusion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "epochs = 200\n",
    "history_fusion, best_model_fusion, best_model_score_fusion = train_save_best(model=model_fusion,\n",
    "                                                                             iterator=train_iter,\n",
    "                                                                             optimizer=opt_fusion,\n",
    "                                                                             criterion=loss_fn_fusion,\n",
    "                                                                             epoch=epochs,\n",
    "                                                                             clip=1,\n",
    "                                                                             device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(best_model_fusion, f'./Models/{model_name}')\n",
    "\n",
    "# save history\n",
    "with open(f'./Models/history_{model_name}.txt', 'w') as dat:\n",
    "    dat.write(str(history_fusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load best model (current model is trained on full epochs)\n",
    "model_fusion.load_state_dict(best_model_fusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Test fusion (after retraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test with vanilla fusion\n",
    "test_fusion(modelA, modelB, model_fusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "b1744cd9dc0832a8d503a2c77e6bee76d4493b3bf33a738cf38afd0bb2e60262"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

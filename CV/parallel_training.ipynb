{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchtext.data import Field, BucketIterator\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import re\n",
    "from transformers import BertTokenizer\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchmetrics.classification import F1Score\n",
    "import optuna\n",
    "import warnings\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from utils import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "'cuda'"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "SEED = 2020"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "# load data\n",
    "train_setA = pd.read_csv(\"./Datasets/sentiment140_processed_21_30000.csv\", encoding='ISO-8859-1')\n",
    "train_setB = pd.read_csv(\"./Datasets/sentiment140_processed_22_30000.csv\", encoding='ISO-8859-1')\n",
    "test_set = pd.read_csv(\"./Datasets/sentiment140_processed_26_60000.csv\", encoding='ISO-8859-1')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing the data...\n",
      "Length of the data :  30000\n",
      "CPU times: total: 28.7 s\n",
      "Wall time: 32.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# preprocessing (tokenization, discard long sentence, lowercase etc.)\n",
    "train_setA = preproc(train_setA)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing the data...\n",
      "Length of the data :  29999\n",
      "CPU times: total: 26.6 s\n",
      "Wall time: 28.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# preprocessing (tokenization, discard long sentence, lowercase etc.)\n",
    "train_setB = preproc(train_setB)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing the data...\n",
      "Length of the data :  59999\n",
      "CPU times: total: 47.5 s\n",
      "Wall time: 49.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# preprocessing (tokenization, discard long sentence, lowercase etc.)\n",
    "test_set = preproc(test_set)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size A:  13911\n"
     ]
    }
   ],
   "source": [
    "# build vocab\n",
    "vocabA = {'__PAD__': 0, '__</e>__': 1, '__UNK__': 2}\n",
    "for item in train_setA.iloc[:, 0]:\n",
    "    for word in item:\n",
    "        if word not in vocabA:\n",
    "            vocabA[word] = len(vocabA)\n",
    "pad_idxA = vocabA['__PAD__']\n",
    "voc_sizeA = len(vocabA)\n",
    "print(\"Vocabulary Size A: \", voc_sizeA)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size B:  13971\n"
     ]
    }
   ],
   "source": [
    "# build vocab\n",
    "vocabB = {'__PAD__': 0, '__</e>__': 1, '__UNK__': 2}\n",
    "for item in train_setB.iloc[:, 0]:\n",
    "    for word in item:\n",
    "        if word not in vocabB:\n",
    "            vocabB[word] = len(vocabB)\n",
    "pad_idxB = vocabB['__PAD__']\n",
    "voc_sizeB = len(vocabB)\n",
    "print(\"Vocabulary Size B: \", voc_sizeB)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size B:  17290\n"
     ]
    }
   ],
   "source": [
    "# build vocab\n",
    "vocab_test = {'__PAD__': 0, '__</e>__': 1, '__UNK__': 2}\n",
    "for item in test_set.iloc[:, 0]:\n",
    "    for word in item:\n",
    "        if word not in vocab_test:\n",
    "            vocab_test[word] = len(vocab_test)\n",
    "pad_idx_test = vocab_test['__PAD__']\n",
    "voc_size_test = len(vocab_test)\n",
    "print(\"Vocabulary Size B: \", voc_size_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "paramsA = torch.load('./Models/modelA_sentiment140_processed_1_256')\n",
    "paramsB = torch.load('./Models/modelA_sentiment140_processed_2_256')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "embeddingA = paramsA['encoder.emb.tok_emb.embedding.weight']\n",
    "embeddingB = paramsB['encoder.emb.tok_emb.embedding.weight']\n",
    "\n",
    "del paramsA['encoder.emb.tok_emb.embedding.weight']\n",
    "del paramsB['encoder.emb.tok_emb.embedding.weight']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "# create models\n",
    "modelA = new_model(embeddingA, pad_idxA, voc_sizeA, device) # init model\n",
    "modelB = new_model(embeddingB, pad_idxB, voc_sizeB, device) # init model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load weights\n",
    "modelA.load_state_dict(paramsA)\n",
    "modelB.load_state_dict(paramsB)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CV"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Definition"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "LEARNING_RATE = 2e-4 # starting learning rate for scheduler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "model_names = ['A', 'B', 'vanilla_pre', 'vanilla_post', 'OT_pre', 'OT_post', 'random']\n",
    "scores = {'loss': {model_name: [] for model_name in model_names},\n",
    "          'accuracy': {model_name: [] for model_name in model_names},\n",
    "          'f1': {model_name: [] for model_name in model_names},}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "'# data generators\\ndef get_generator(train_set, test_set, voc_train, voc_test, batch_size=512):\\n    # dataframe to tensor\\n    train_y = torch.tensor(train_set.iloc[:, 1].values.astype(np.float32), device=device)\\n    test_y = torch.tensor(test_set.iloc[:, 1].values.astype(np.float32), device=device)\\n\\n    unk_ID = voc[\"__UNK__\"]\\n\\n    train_x_tensor = []\\n    for idx, text_corpus in enumerate(tqdm(train_set.iloc[:, 0])):\\n        foo = []\\n        for token in text_corpus:\\n            word_ID = voc.get(token, unk_ID)\\n            foo.append(word_ID)\\n        while len(foo) < 256:\\n            foo.append(voc[\"__PAD__\"])\\n        train_x_tensor.append(foo)\\n\\n    test_x_tensor = []\\n    for idx, text_corpus in enumerate(tqdm(test_set.iloc[:, 0])):\\n        foo = []\\n        for token in text_corpus:\\n            word_ID = voc.get(token, unk_ID)\\n            foo.append(word_ID)\\n        while len(foo) < 256:\\n            foo.append(voc[\"__PAD__\"])\\n        test_x_tensor.append(foo)\\n\\n    train_x = torch.tensor(train_x_tensor, device=device)\\n    test_x = torch.tensor(test_x_tensor, device=device)\\n\\n    train = torch.utils.data.TensorDataset(train_x, train_y)\\n    test = torch.utils.data.TensorDataset(test_x, test_y)\\n\\n    train_iterator = torch.utils.data.DataLoader(dataset=train, batch_size=batch_size, shuffle=True)\\n    test_iterator = torch.utils.data.DataLoader(dataset=test, batch_size=batch_size, shuffle=True)\\n\\n    # check imbalance\\n    check_imbalance(train_iterator, name=\\'train set\\')\\n    check_imbalance(test_iterator, name=\\'test set\\')\\n\\n    print(\\'Dataset initializing done\\')\\n\\n    return train_iterator, test_iterator'"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# data generators\n",
    "def get_generator(train_set, test_set, voc_train, voc_test, batch_size=512):\n",
    "    # dataframe to tensor\n",
    "    train_y = torch.tensor(train_set.iloc[:, 1].values.astype(np.float32), device=device)\n",
    "    test_y = torch.tensor(test_set.iloc[:, 1].values.astype(np.float32), device=device)\n",
    "\n",
    "    unk_ID = voc[\"__UNK__\"]\n",
    "\n",
    "    train_x_tensor = []\n",
    "    for idx, text_corpus in enumerate(tqdm(train_set.iloc[:, 0])):\n",
    "        foo = []\n",
    "        for token in text_corpus:\n",
    "            word_ID = voc.get(token, unk_ID)\n",
    "            foo.append(word_ID)\n",
    "        while len(foo) < 256:\n",
    "            foo.append(voc[\"__PAD__\"])\n",
    "        train_x_tensor.append(foo)\n",
    "\n",
    "    test_x_tensor = []\n",
    "    for idx, text_corpus in enumerate(tqdm(test_set.iloc[:, 0])):\n",
    "        foo = []\n",
    "        for token in text_corpus:\n",
    "            word_ID = voc.get(token, unk_ID)\n",
    "            foo.append(word_ID)\n",
    "        while len(foo) < 256:\n",
    "            foo.append(voc[\"__PAD__\"])\n",
    "        test_x_tensor.append(foo)\n",
    "\n",
    "    train_x = torch.tensor(train_x_tensor, device=device)\n",
    "    test_x = torch.tensor(test_x_tensor, device=device)\n",
    "\n",
    "    train = torch.utils.data.TensorDataset(train_x, train_y)\n",
    "    test = torch.utils.data.TensorDataset(test_x, test_y)\n",
    "\n",
    "    train_iterator = torch.utils.data.DataLoader(dataset=train, batch_size=batch_size, shuffle=True)\n",
    "    test_iterator = torch.utils.data.DataLoader(dataset=test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # check imbalance\n",
    "    check_imbalance(train_iterator, name='train set')\n",
    "    check_imbalance(test_iterator, name='test set')\n",
    "\n",
    "    print('Dataset initializing done')\n",
    "\n",
    "    return train_iterator, test_iterator\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "# data generators\n",
    "def get_generator(dataset, voc, batch_size=512, name=''):\n",
    "    # dataframe to tensor\n",
    "    y = torch.tensor(dataset.iloc[:, 1].values.astype(np.float32), device=device)\n",
    "\n",
    "    unk_ID = voc[\"__UNK__\"]\n",
    "\n",
    "    x_tensor = []\n",
    "    for idx, text_corpus in enumerate(tqdm(dataset.iloc[:, 0])):\n",
    "        foo = []\n",
    "        for token in text_corpus:\n",
    "            word_ID = voc.get(token, unk_ID)\n",
    "            foo.append(word_ID)\n",
    "        while len(foo) < 256:\n",
    "            foo.append(voc[\"__PAD__\"])\n",
    "        x_tensor.append(foo)\n",
    "\n",
    "    x_tensor = torch.tensor(x_tensor, device=device)\n",
    "    tensor_dataset = torch.utils.data.TensorDataset(x_tensor, y)\n",
    "    iterator = torch.utils.data.DataLoader(dataset=tensor_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # check imbalance\n",
    "    check_imbalance(iterator, name=name)\n",
    "\n",
    "    print('Dataset initializing done')\n",
    "    return iterator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:01<00:00, 19893.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive labels ratio (A): 0.0\n",
      "Dataset initializing done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29999/29999 [00:01<00:00, 24731.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive labels ratio (B): 0.0\n",
      "Dataset initializing done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59999/59999 [00:02<00:00, 24212.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive labels ratio (test): 1.0\n",
      "Dataset initializing done\n",
      "CPU times: total: 8.91 s\n",
      "Wall time: 8.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    # build generators\n",
    "    train_iteratorA = get_generator(train_setA, vocabA, batch_size=512, name='A')\n",
    "    train_iteratorB = get_generator(train_setB, vocabB, batch_size=512, name='B')\n",
    "    test_iterator = get_generator(test_set, vocab_test, batch_size=512, name='test')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FOLDS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[1;32m<timed exec>:3\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'FOLDS' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    for i in range(FOLDS):\n",
    "        print(f'Fold {i + 1}/{FOLDS}')\n",
    "\n",
    "        # get training, test set\n",
    "        train_set, test_set = datasets.pop()\n",
    "\n",
    "        # build generators\n",
    "        train_iterator, test_iterator, voc_size, pad_idx, embedding = build_generators(train_set, test_set, device, batch_size=512)\n",
    "\n",
    "        # train parent models\n",
    "        train_parent = lambda x: train_early_stopping(model_name=x,\n",
    "                                                      train_iter=train_iterator,\n",
    "                                                      valid_iter=test_iterator,\n",
    "                                                      embedding=embedding,\n",
    "                                                      pad_idx=pad_idx,\n",
    "                                                      voc_size=voc_size,\n",
    "                                                      device=device,\n",
    "                                                      lr=LEARNING_RATE,\n",
    "                                                      save=False)\n",
    "        print('Starting training for model A')\n",
    "        modelA = train_parent('A')\n",
    "        print('Starting training for model B')\n",
    "        modelB = train_parent('B')\n",
    "\n",
    "        # model fusion\n",
    "        # 1) vanilla\n",
    "        model_fusion_vanilla = vanilla_fusion(modelA=modelA, modelB=modelB, pad_idx=pad_idx, voc_size=voc_size, embedding=embedding, device=device)\n",
    "        # 2) optimal transport\n",
    "        N_TRIALS = 100\n",
    "        study = optuna.create_study()\n",
    "        study.optimize(weighted_fusion(modelA, modelB, train_iterator, test_iterator, embedding, pad_idx, voc_size, device), n_trials=N_TRIALS)\n",
    "        best_weighting_factor = study.best_params['weighting_factor']\n",
    "        print('Best fusion weight:', best_weighting_factor)\n",
    "        model_fusion = ot_fusion(modelA, modelB, train_iterator, embedding, pad_idx, voc_size, device, fusion_ratio=best_weighting_factor)\n",
    "\n",
    "        # evaluate\n",
    "        # ensure all models on same device\n",
    "        model_to_cpu = lambda x: x.to(device)\n",
    "        modelA = model_to_cpu(modelA)\n",
    "        modelB = model_to_cpu(modelB)\n",
    "        model_random = new_model(embedding, pad_idx, voc_size, device)\n",
    "        model_fusion = model_to_cpu(model_fusion)\n",
    "        model_fusion_vanilla = model_to_cpu(model_fusion_vanilla)\n",
    "\n",
    "        # test models\n",
    "        for name, model in zip(('A', 'B', 'random', 'OT_pre', 'vanilla_pre'), (modelA, modelB, model_random, model_fusion, model_fusion_vanilla)):\n",
    "            loss, acc, f1 = validation(model, test_iterator, nn.CrossEntropyLoss(), device) # (loss, accuracy, f1)\n",
    "\n",
    "            # put into cpu\n",
    "            to_cpu = lambda x: x.to('cpu') if isinstance(x, torch.Tensor) else x\n",
    "            loss = to_cpu(loss)\n",
    "            acc = to_cpu(acc)\n",
    "            f1 = to_cpu(f1)\n",
    "\n",
    "            print(name, f'loss: {loss} - accuracy: {acc} - f1: {f1}')\n",
    "            scores['loss'][name].append(loss), scores['accuracy'][name].append(acc), scores['f1'][name].append(f1)\n",
    "\n",
    "        # retraining\n",
    "        retrain = lambda x: train(model=x,\n",
    "                                  iterator=train_iterator,\n",
    "                                  valid_iter=test_iterator,\n",
    "                                  optimizer=torch.optim.SGD(x.parameters(), lr=LEARNING_RATE),\n",
    "                                  criterion=nn.CrossEntropyLoss(),\n",
    "                                  epoch='unrestricted',\n",
    "                                  clip=1,\n",
    "                                  device=device)\n",
    "        # 1) vanilla\n",
    "        # train with early stopping\n",
    "        print('Starting retraining for model vanilla fusion')\n",
    "        retrain(model_fusion_vanilla)\n",
    "\n",
    "        # 2) optimal transport\n",
    "        # train with early stopping\n",
    "        print('Starting retraining for model OT fusion')\n",
    "        retrain(model_fusion)\n",
    "\n",
    "        # evaluate\n",
    "        # ensure all models on same device\n",
    "        model_fusion = model_to_cpu(model_fusion)\n",
    "        model_fusion_vanilla = model_to_cpu(model_fusion_vanilla)\n",
    "\n",
    "        # test models\n",
    "        for name, model in zip(('OT_post', 'vanilla_post'), (model_fusion, model_fusion_vanilla)):\n",
    "            loss, acc, f1 = validation(model, test_iterator, nn.CrossEntropyLoss(), device) # (loss, accuracy, f1)\n",
    "\n",
    "            # put into cpu\n",
    "            to_cpu = lambda x: x.to('cpu') if isinstance(x, torch.Tensor) else x\n",
    "            loss = to_cpu(loss)\n",
    "            acc = to_cpu(acc)\n",
    "            f1 = to_cpu(f1)\n",
    "\n",
    "            print(name, f'loss: {loss} - accuracy: {acc} - f1: {f1}')\n",
    "            scores['loss'][name].append(loss), scores['accuracy'][name].append(acc), scores['f1'][name].append(f1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Export as LaTeX"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "model_names_latex = ['Model A', 'Model B', 'Vanilla', 'Vanilla (retraining)', 'Optimal transport', 'Optimal transport (retraining)', 'Untrained model (baseline)']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             loss accuracy  f1\n",
      "A              []       []  []\n",
      "B              []       []  []\n",
      "vanilla_pre    []       []  []\n",
      "vanilla_post   []       []  []\n",
      "OT_pre         []       []  []\n",
      "OT_post        []       []  []\n",
      "random         []       []  []\n",
      "\\begin{table}[H]\n",
      "\\centering\n",
      "\\caption{Model performance (5-fold CV)}\n",
      "\\begin{tabular}{llll}\n",
      "\\toprule\n",
      "{} &             Loss &         Accuracy &         F1 score \\\\\n",
      "\\midrule\n",
      "\\textbf{Model A                       } &  \\textbf{nan ± nan} &  \\textbf{nan ± nan} &  \\textbf{nan ± nan} \\\\\n",
      "\\textbf{Model B                       } &        nan ± nan &        nan ± nan &        nan ± nan \\\\\n",
      "\\textbf{Vanilla                       } &        nan ± nan &        nan ± nan &        nan ± nan \\\\\n",
      "\\textbf{Vanilla (retraining)          } &        nan ± nan &        nan ± nan &        nan ± nan \\\\\n",
      "\\textbf{Optimal transport             } &        nan ± nan &        nan ± nan &        nan ± nan \\\\\n",
      "\\textbf{Optimal transport (retraining)} &        nan ± nan &        nan ± nan &        nan ± nan \\\\\n",
      "\\textbf{Untrained model (baseline)    } &        nan ± nan &        nan ± nan &        nan ± nan \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jjung\\anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\jjung\\anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\jjung\\anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\jjung\\anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "C:\\Users\\jjung\\anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\jjung\\OneDrive\\Dokumente\\ETH\\MSc 3rd semester\\Deep Learning\\DL Project\\CV\\utils.py:1010: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex = df.to_latex(index=True,\n"
     ]
    }
   ],
   "source": [
    "latex = scores_to_latex(scores, model_names_latex)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# save as latex (in text format) (optional)\n",
    "with open('./Output/scores_different_seeds (weighted full retraining).txt','w') as dat:\n",
    "    dat.write(str(latex))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "b1744cd9dc0832a8d503a2c77e6bee76d4493b3bf33a738cf38afd0bb2e60262"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
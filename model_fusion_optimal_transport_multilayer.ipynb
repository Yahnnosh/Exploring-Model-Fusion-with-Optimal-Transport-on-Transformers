{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import TransformerClassifier\n",
    "from dataloader import *\n",
    "from utils import *\n",
    "import torch\n",
    "import ot\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset initializing start\n",
      "Tokenizing the data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\atace\\OneDrive\\Desktop\\ETH\\9.Semester\\Deep Learning\\project\\Exploring-Model-Fusion-with-Optimal-Transport-on-Transformers\\dataloader.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"len\"] = data.iloc[:, 0].apply(lambda x : len(self.tokenize(x)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the data :  29544\n",
      "0\n",
      "review       [[CLS], one, of, the, many, silent, comedies, ...\n",
      "sentiment                                                    0\n",
      "len                                                        186\n",
      "Name: 46539, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23635/23635 [00:03<00:00, 7592.40it/s]\n",
      "100%|██████████| 2954/2954 [00:00<00:00, 7348.25it/s]\n",
      "100%|██████████| 2955/2955 [00:00<00:00, 4323.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset initializing done\n",
      "Vocabulary Size :  23050\n"
     ]
    }
   ],
   "source": [
    "#init\n",
    "tokenizer = Tokenizer()\n",
    "loader = DataLoader(tokenize = tokenizer.tokenize)\n",
    "\n",
    "# import data (combine train/test as we split afterwards anyways)\n",
    "data = pd.read_csv(\"./Data/IMDB Dataset.csv\", encoding='ISO-8859-1')\n",
    "# convert string label to binary (int) label (spam:1, non-spam:0)\n",
    "data[\"sentiment\"] = data['sentiment'].apply(lambda x : int(x == \"positive\"))\n",
    "\n",
    "# train, test, val split\n",
    "train, valid, test = loader.make_dataset(data)\n",
    "vocab = loader.get_vocab(train.iloc[:, 0])\n",
    "train_iter, valid_iter, test_iter = loader.make_iter(train, valid, test,\n",
    "                                                     batch_size=512,\n",
    "                                                     device=device)\n",
    "\n",
    "# NLP stuff\n",
    "pad_idx = vocab['__PAD__']\n",
    "voc_size = len(vocab)\n",
    "print(\"Vocabulary Size : \", voc_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the embedding matrix\n",
    "embedding = torch.load(\"Models/embedding_16.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerClassifier(\n",
       "  (encoder): Encoder(\n",
       "    (emb): TransformerEmbedding(\n",
       "      (tok_emb): TokenEmbedding(\n",
       "        (embedding): Embedding(23050, 16)\n",
       "      )\n",
       "      (pos_emb): PositionalEncoding()\n",
       "      (drop_out): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (attention): MultiHeadAttention(\n",
       "          (attention): ScaleDotProductAttention(\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (w_q): Linear(in_features=16, out_features=16, bias=True)\n",
       "          (w_k): Linear(in_features=16, out_features=16, bias=True)\n",
       "          (w_v): Linear(in_features=16, out_features=16, bias=True)\n",
       "          (w_concat): Linear(in_features=16, out_features=16, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (dropout1): Dropout(p=0.5, inplace=False)\n",
       "        (ffn): PositionwiseFeedForward(\n",
       "          (linear1): Linear(in_features=16, out_features=32, bias=True)\n",
       "          (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "        (norm2): LayerNorm()\n",
       "        (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (1): EncoderLayer(\n",
       "        (attention): MultiHeadAttention(\n",
       "          (attention): ScaleDotProductAttention(\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (w_q): Linear(in_features=16, out_features=16, bias=True)\n",
       "          (w_k): Linear(in_features=16, out_features=16, bias=True)\n",
       "          (w_v): Linear(in_features=16, out_features=16, bias=True)\n",
       "          (w_concat): Linear(in_features=16, out_features=16, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (dropout1): Dropout(p=0.5, inplace=False)\n",
       "        (ffn): PositionwiseFeedForward(\n",
       "          (linear1): Linear(in_features=16, out_features=32, bias=True)\n",
       "          (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "        (norm2): LayerNorm()\n",
       "        (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=4096, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelA = TransformerClassifier(src_pad_idx = pad_idx,\n",
    "                              embedding=embedding,\n",
    "                              enc_voc_size = voc_size,\n",
    "                              max_len = 256,\n",
    "                              d_model = 16,\n",
    "                              ffn_hidden = 32,\n",
    "                              n_head = 1,\n",
    "                              n_layers = 2,\n",
    "                              drop_prob = 0.5,\n",
    "                              device = device)\n",
    "\n",
    "modelA.load_state_dict(torch.load(\"Models\\modelA_IMDB_256_multilayer\"))\n",
    "modelA.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerClassifier(\n",
       "  (encoder): Encoder(\n",
       "    (emb): TransformerEmbedding(\n",
       "      (tok_emb): TokenEmbedding(\n",
       "        (embedding): Embedding(23050, 16)\n",
       "      )\n",
       "      (pos_emb): PositionalEncoding()\n",
       "      (drop_out): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (attention): MultiHeadAttention(\n",
       "          (attention): ScaleDotProductAttention(\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (w_q): Linear(in_features=16, out_features=16, bias=True)\n",
       "          (w_k): Linear(in_features=16, out_features=16, bias=True)\n",
       "          (w_v): Linear(in_features=16, out_features=16, bias=True)\n",
       "          (w_concat): Linear(in_features=16, out_features=16, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (dropout1): Dropout(p=0.5, inplace=False)\n",
       "        (ffn): PositionwiseFeedForward(\n",
       "          (linear1): Linear(in_features=16, out_features=32, bias=True)\n",
       "          (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "        (norm2): LayerNorm()\n",
       "        (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (1): EncoderLayer(\n",
       "        (attention): MultiHeadAttention(\n",
       "          (attention): ScaleDotProductAttention(\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (w_q): Linear(in_features=16, out_features=16, bias=True)\n",
       "          (w_k): Linear(in_features=16, out_features=16, bias=True)\n",
       "          (w_v): Linear(in_features=16, out_features=16, bias=True)\n",
       "          (w_concat): Linear(in_features=16, out_features=16, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (dropout1): Dropout(p=0.5, inplace=False)\n",
       "        (ffn): PositionwiseFeedForward(\n",
       "          (linear1): Linear(in_features=16, out_features=32, bias=True)\n",
       "          (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "        (norm2): LayerNorm()\n",
       "        (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=4096, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelB = TransformerClassifier(src_pad_idx = pad_idx,\n",
    "                              embedding=embedding,\n",
    "                              enc_voc_size = voc_size,\n",
    "                              max_len = 256,\n",
    "                              d_model = 16,\n",
    "                              ffn_hidden = 32,\n",
    "                              n_head = 1,\n",
    "                              n_layers = 2,\n",
    "                              drop_prob = 0.5,\n",
    "                              device = device)\n",
    "\n",
    "modelB.load_state_dict(torch.load(\"Models\\modelB_IMDB_256_multilayer\"))\n",
    "modelB.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OT Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSupport(model, trainloader, l, alignment = \"acts\", numOfBatches= 10):\n",
    "    '''\n",
    "    Get the support matrices using Activation-based (\"acts\") or Weight-based (\"wts\") alignment \n",
    "    '''\n",
    "    if alignment == \"acts\":\n",
    "        activation = None\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            if i >= numOfBatches:\n",
    "                break\n",
    "            \n",
    "            inputs, targets = data\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            if activation is None:\n",
    "                activation = model.actMatrix[l]\n",
    "            else:\n",
    "                activation = torch.cat((activation, model.actMatrix[l]))\n",
    "\n",
    "        return activation\n",
    "    elif alignment == \"wts\":\n",
    "        return model.state_dict()[l]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusion(nameA, nameB, weightA, weightB, transport_matrix, beta):\n",
    "    support_y = getSupport(modelB, train_iter, nameB, alignment=\"wts\")\n",
    "    # Get the weights at layer \"idx\" from the first model\n",
    "    W_A = weightA\n",
    "    W_B = weightB\n",
    "    # Align the weights from the first model\n",
    "    aligned_W = torch.matmul(W_A, torch.matmul(transport_matrix, torch.diag(1 / beta)))\n",
    "    # Get the X-Support\n",
    "    n = W_A.shape[0]\n",
    "    alpha = torch.ones(n) * (1/n)\n",
    "    support_x = getSupport(modelA, train_iter, nameA, alignment=\"wts\")\n",
    "    # Calculate the euclidean distance between the supports\n",
    "    distance = ot.dist(support_x, support_y)\n",
    "    # Calculate beta\n",
    "    m = W_B.shape[0]\n",
    "    beta = torch.ones(m) * (1/m)\n",
    "    # Calculate the transport matrix using optimal transport\n",
    "    transport_matrix = torch.from_numpy(ot.emd(alpha.numpy(), beta.numpy(), distance.detach().numpy())).float().reshape((n, m))\n",
    "    # Align model neurons\n",
    "    aligned_model = torch.matmul(torch.diag(1 / beta), torch.matmul(transport_matrix.T, aligned_W))\n",
    "    # Get the weights at layer \"idx\" from the second model\n",
    "    fused = (aligned_model + W_B) / 2 \n",
    "    return  fused, transport_matrix, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusion_multilayer(nameA, nameB, weightA, weightB, transport_matrix, beta, layers):\n",
    "    layer = int(nameA.partition(\"layers.\")[2][0])\n",
    "    \n",
    "    W_A = torch.empty((weightA.shape[0] * layers, weightA.shape[1]))\n",
    "    W_B = torch.empty((weightB.shape[0] * layers, weightB.shape[1]))\n",
    "\n",
    "    for l in range(layers):\n",
    "        W_A[l * weightB.shape[0] : l * weightB.shape[0] + weightB.shape[0], :] = modelA.state_dict()[nameA.replace(f\"layers.{layer}\", f\"layers.{l}\")]\n",
    "        W_B[l * weightB.shape[0] : l * weightB.shape[0] + weightB.shape[0], :] = modelB.state_dict()[nameA.replace(f\"layers.{layer}\", f\"layers.{l}\")]\n",
    "\n",
    "    support_y = W_B\n",
    "    support_x = W_A\n",
    "\n",
    "    # Initialize the fused model and transport matrix\n",
    "    fused = torch.empty(W_B.shape)\n",
    "    transport_matrix_new = torch.zeros((W_A.shape[0], W_B.shape[0]))\n",
    "    # Align the weights from the first model\n",
    "    aligned_W = torch.matmul(W_A, torch.matmul(transport_matrix, torch.diag(1 / beta)))\n",
    "    # Get the X-Support\n",
    "    n = W_A.shape[0]\n",
    "    alpha = torch.ones(n) * (1/n)\n",
    "    # Calculate the euclidean distance between the supports\n",
    "    distance = ot.dist(support_x, support_y)\n",
    "    # Calculate beta\n",
    "    m = W_B.shape[0]\n",
    "    beta = torch.ones(m) * (1/m)\n",
    "    # Calculate the transport matrix using optimal transport\n",
    "    transport_matrix = torch.from_numpy(ot.emd(alpha.numpy(), beta.numpy(), distance.detach().numpy())).float().reshape((n, m))\n",
    "    # Align model neurons\n",
    "    aligned_model = torch.matmul(torch.diag(1 / beta), torch.matmul(transport_matrix.T, aligned_W))\n",
    "    # Get the weights at layer \"idx\" from the second model\n",
    "    fused = (aligned_model + W_B) / 2\n",
    "    dim = layer * weightB.shape[0]\n",
    "    dim_to = layer * weightB.shape[0] + weightB.shape[0]\n",
    "    return  fused[dim:dim_to, :], transport_matrix_new[dim:dim_to, dim:dim_to], beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusion_multihead_multilayer(nameA, nameB, weightA, weightB, transport_matrix, beta, heads, layers):\n",
    "    layer = int(nameA.partition(\"layers.\")[2][0])\n",
    "    \n",
    "    W_A = torch.empty((weightA.shape[0] * layers, weightA.shape[1]))\n",
    "    W_B = torch.empty((weightB.shape[0] * layers, weightB.shape[1]))\n",
    "    \n",
    "    stride = weightB.shape[0] // heads\n",
    "    for l in range(layers):\n",
    "        W_A[l * weightB.shape[0] : l * weightB.shape[0] + weightB.shape[0], :] = modelA.state_dict()[nameA.replace(f\"layers.{layer}\", f\"layers.{l}\")]\n",
    "        W_B[l * weightB.shape[0] : l * weightB.shape[0] + weightB.shape[0], :] = modelB.state_dict()[nameA.replace(f\"layers.{layer}\", f\"layers.{l}\")]\n",
    "\n",
    "    support_y = W_B\n",
    "    support_x = W_A\n",
    "\n",
    "    # Initialize the fused model and transport matrix\n",
    "    fused = torch.empty(W_B.shape)\n",
    "    transport_matrix_new = torch.zeros((W_A.shape[0], W_B.shape[0]))\n",
    "    stride = W_B.shape[0] // (heads * layers)\n",
    "    for i in range(0, W_B.shape[0], stride):\n",
    "        # Align the weights from the first model\n",
    "        aligned_W = torch.matmul(W_A[i:i+stride, :], torch.matmul(transport_matrix, torch.diag(1 / beta)))\n",
    "        # Get the X-Support\n",
    "        n = W_A.shape[0] // (heads * layers)\n",
    "        alpha = torch.ones(n) * (1/n)\n",
    "        # Calculate the euclidean distance between the supports\n",
    "        distance = ot.dist(support_x[i:i+stride, :], support_y[i:i+stride, :])\n",
    "        # Calculate beta\n",
    "        m = W_B.shape[0] // (heads * layers)\n",
    "        beta_new = torch.ones(m) * (1/m)\n",
    "        # Calculate the transport matrix using optimal transport\n",
    "        transport_matrix_new[i:i+stride, i:i+stride] = torch.from_numpy(ot.emd(alpha.numpy(), beta_new.numpy(), distance.detach().numpy())).float().reshape((n, m))\n",
    "        # Align model neurons\n",
    "        aligned_model = torch.matmul(torch.diag(1 / beta_new), torch.matmul(transport_matrix_new[i:i+stride, i:i+stride].T, aligned_W))\n",
    "        # Get the weights at layer \"idx\" from the second model\n",
    "        fused[i:i+stride, :] = (aligned_model + W_B[i:i+stride, :]) / 2 \n",
    "    dim = layer * weightB.shape[0]\n",
    "    dim_to = layer * weightB.shape[0] + weightB.shape[0]\n",
    "    return  fused[dim:dim_to, :], transport_matrix_new[dim:dim_to, dim:dim_to], beta_new"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fusion via Optimal Transport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {'loss': {'A_test_set': [], 'B_test_set': [], 'OT_pre': [], 'OT_calibr': [], 'OT_last_layer': [], 'OT_test_set' : []},\n",
    "          'accuracy': {'A_test_set': [], 'B_test_set': [], 'OT_pre': [], 'OT_calibr': [], 'OT_last_layer': [], 'OT_test_set' : []},\n",
    "          'f1': {'A_test_set': [], 'B_test_set': [], 'OT_pre': [], 'OT_calibr': [], 'OT_last_layer': [], 'OT_test_set' : []}}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusedModel = TransformerClassifier(src_pad_idx = pad_idx,\n",
    "                              embedding = embedding,\n",
    "                              enc_voc_size = voc_size,\n",
    "                              max_len = 256,\n",
    "                              d_model = 16,\n",
    "                              ffn_hidden = 32,\n",
    "                              n_head = 1,\n",
    "                              n_layers = 2,\n",
    "                              drop_prob = 0.2,\n",
    "                              device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj(trial):\n",
    "    a = trial.suggest_float('a', 0, 1)\n",
    "    \n",
    "    # Create the fused weights matrix\n",
    "    W_fusion = dict.fromkeys(list(modelA.state_dict().keys()))\n",
    "    # Initialize the algorithm\n",
    "    m = list(modelB.state_dict().items())[1][1].shape[1]\n",
    "    beta = torch.ones(m) * (1/m)\n",
    "    transport_matrix = torch.matmul(torch.diag(beta), torch.eye(m))\n",
    "\n",
    "    # Fusion via Optimal Transport\n",
    "    for (nameA, weightA), (nameB, weightB) in zip(modelA.named_parameters(), modelB.named_parameters()):\n",
    "        if nameA == \"encoder.emb.tok_emb.embedding.weight\":\n",
    "            W_fusion[nameA] = weightA\n",
    "        else:   \n",
    "            if \"weight\" in nameA:\n",
    "                if \"encoder\" in nameA:\n",
    "                    if \"concat\" not in nameA and \"linear\" not in nameA: \n",
    "                        transport_matrix_triplet = torch.empty((weightA.shape[0], weightB.shape[0]))\n",
    "                        W_fusion[nameA], transport_matrix_triplet, _ = fusion_multilayer(nameA, nameB, weightA, weightB, transport_matrix, beta, 2)\n",
    "                    else:\n",
    "                        W_fusion[nameA], transport_matrix, beta = fusion(nameA, nameB, weightA, weightB, transport_matrix, beta)\n",
    "\n",
    "                else:\n",
    "                    W_fusion[nameA] = a * weightA + (1-a) * weightB\n",
    "            elif \"bias\" in nameA:\n",
    "                if \"encoder\" in nameA: \n",
    "                    if \"concat\" not in nameA and \"linear\" not in nameA: \n",
    "                        m = weightB.shape[0]\n",
    "                        beta_bias = torch.ones(m) * (1/m)\n",
    "                        W_A_bias = weightA.reshape(m, 1)\n",
    "                        aligned_bias = torch.matmul(torch.diag(1 / beta_bias), torch.matmul(transport_matrix_triplet.T, W_A_bias))\n",
    "                        aligned_bias = aligned_bias.reshape(m)\n",
    "                        W_fusion[nameA] = (aligned_bias + weightB) / 2\n",
    "                    else:\n",
    "                        m = weightB.shape[0]\n",
    "                        beta_bias = torch.ones(m) * (1/m)\n",
    "                        W_A_bias = weightA.reshape(m, 1)\n",
    "                        aligned_bias = torch.matmul(torch.diag(1 / beta_bias), torch.matmul(transport_matrix.T, W_A_bias))\n",
    "                        aligned_bias = aligned_bias.reshape(m)\n",
    "                        W_fusion[nameA] = (aligned_bias + weightB) / 2\n",
    "                else:\n",
    "                    W_fusion[nameA] = a * weightA + (1-a) * weightB\n",
    "            else:\n",
    "                W_fusion[nameA] = a * weightA + (1-a) * weightB\n",
    "\n",
    "    # Assign the weights\n",
    "    with torch.no_grad():\n",
    "        for name, param in fusedModel.named_parameters():\n",
    "            param.data = torch.nn.Parameter(W_fusion[name])\n",
    "\n",
    "    # Validate the fused model\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    val_loss, val_acc, val_f1 = validation(fusedModel, valid_iter, None, criterion, device)\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-30 16:56:08,884]\u001b[0m A new study created in memory with name: no-name-e1ebd106-0f98-485f-a676-417bc2ebc8ae\u001b[0m\n",
      "c:\\Users\\atace\\OneDrive\\Desktop\\ETH\\9.Semester\\Deep Learning\\project\\Exploring-Model-Fusion-with-Optimal-Transport-on-Transformers\\utils.py:159: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  src, trg = torch.tensor(src).to(device), torch.tensor(trg).to(device)  # put to cpu/gpu\n",
      "\u001b[32m[I 2022-12-30 16:56:20,988]\u001b[0m Trial 0 finished with value: 0.8179209729035696 and parameters: {'a': 0.8970449330060377}. Best is trial 0 with value: 0.8179209729035696.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 16:56:32,516]\u001b[0m Trial 1 finished with value: 2.98838218053182 and parameters: {'a': 0.003952219253880895}. Best is trial 0 with value: 0.8179209729035696.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 16:56:43,397]\u001b[0m Trial 2 finished with value: 0.9196842014789581 and parameters: {'a': 0.8180080947523416}. Best is trial 0 with value: 0.8179209729035696.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 16:56:53,306]\u001b[0m Trial 3 finished with value: 1.1408438086509705 and parameters: {'a': 0.6931171086467981}. Best is trial 0 with value: 0.8179209729035696.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 16:57:02,673]\u001b[0m Trial 4 finished with value: 2.226850946744283 and parameters: {'a': 0.2595682121055255}. Best is trial 0 with value: 0.8179209729035696.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 16:57:12,919]\u001b[0m Trial 5 finished with value: 2.0030295054117837 and parameters: {'a': 0.3410906211892951}. Best is trial 0 with value: 0.8179209729035696.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 16:57:25,118]\u001b[0m Trial 6 finished with value: 0.9776491125424703 and parameters: {'a': 0.7819913924698859}. Best is trial 0 with value: 0.8179209729035696.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 16:57:34,922]\u001b[0m Trial 7 finished with value: 2.492676774660746 and parameters: {'a': 0.16646797584860218}. Best is trial 0 with value: 0.8179209729035696.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 16:57:44,018]\u001b[0m Trial 8 finished with value: 1.1148144205411274 and parameters: {'a': 0.7098474443474829}. Best is trial 0 with value: 0.8179209729035696.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 16:57:52,570]\u001b[0m Trial 9 finished with value: 1.3096946477890015 and parameters: {'a': 0.6169784798736153}. Best is trial 0 with value: 0.8179209729035696.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 16:58:01,630]\u001b[0m Trial 10 finished with value: 0.7611475189526876 and parameters: {'a': 0.9691333160170506}. Best is trial 10 with value: 0.7611475189526876.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 16:58:12,004]\u001b[0m Trial 11 finished with value: 0.7510393957297007 and parameters: {'a': 0.9926883017050414}. Best is trial 11 with value: 0.7510393957297007.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 16:58:23,285]\u001b[0m Trial 12 finished with value: 0.7600255906581879 and parameters: {'a': 0.9756828494307239}. Best is trial 11 with value: 0.7510393957297007.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 16:58:33,698]\u001b[0m Trial 13 finished with value: 1.656281054019928 and parameters: {'a': 0.4703071646175022}. Best is trial 11 with value: 0.7510393957297007.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 16:58:44,903]\u001b[0m Trial 14 finished with value: 0.7845842738946279 and parameters: {'a': 0.933546985927826}. Best is trial 11 with value: 0.7510393957297007.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 16:58:56,722]\u001b[0m Trial 15 finished with value: 1.4689279596010845 and parameters: {'a': 0.5465759421384779}. Best is trial 11 with value: 0.7510393957297007.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 16:59:07,931]\u001b[0m Trial 16 finished with value: 0.7529952824115753 and parameters: {'a': 0.9943379013140392}. Best is trial 11 with value: 0.7510393957297007.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 16:59:17,109]\u001b[0m Trial 17 finished with value: 0.9530694385369619 and parameters: {'a': 0.7964947548499254}. Best is trial 11 with value: 0.7510393957297007.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 16:59:25,226]\u001b[0m Trial 18 finished with value: 0.748486210902532 and parameters: {'a': 0.9998676515315769}. Best is trial 18 with value: 0.748486210902532.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 16:59:33,489]\u001b[0m Trial 19 finished with value: 0.8551798065503439 and parameters: {'a': 0.8650532672586544}. Best is trial 18 with value: 0.748486210902532.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(obj, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:      0.7510955631732941\n",
      "Validation Accuracy:      0.6117759226945855\n"
     ]
    }
   ],
   "source": [
    "a = study.best_params[\"a\"]\n",
    "\n",
    "# Create the fused weights matrix\n",
    "W_fusion = dict.fromkeys(list(modelA.state_dict().keys()))\n",
    "# Initialize the algorithm\n",
    "m = list(modelB.state_dict().items())[1][1].shape[1]\n",
    "beta = torch.ones(m) * (1/m)\n",
    "transport_matrix = torch.matmul(torch.diag(beta), torch.eye(m))\n",
    "# Fusion via Optimal Transport\n",
    "for (nameA, weightA), (nameB, weightB) in zip(modelA.named_parameters(), modelB.named_parameters()):\n",
    "    if nameA == \"encoder.emb.tok_emb.embedding.weight\":\n",
    "        W_fusion[nameA] = weightA\n",
    "    else:   \n",
    "        if \"weight\" in nameA:\n",
    "            if \"encoder\" in nameA:\n",
    "                if \"concat\" not in nameA and \"linear\" not in nameA: \n",
    "                    transport_matrix_triplet = torch.empty((weightA.shape[0], weightB.shape[0]))\n",
    "                    W_fusion[nameA], transport_matrix_triplet, _ = fusion_multilayer(nameA, nameB, weightA, weightB, transport_matrix, beta, 2)\n",
    "                else:\n",
    "                    W_fusion[nameA], transport_matrix, beta = fusion(nameA, nameB, weightA, weightB, transport_matrix, beta)\n",
    "            else:\n",
    "                W_fusion[nameA] = a * weightA + (1-a) * weightB\n",
    "        elif \"bias\" in nameA:\n",
    "            if \"encoder\" in nameA: \n",
    "                if \"concat\" not in nameA and \"linear\" not in nameA: \n",
    "                    m = weightB.shape[0]\n",
    "                    beta_bias = torch.ones(m) * (1/m)\n",
    "                    W_A_bias = weightA.reshape(m, 1)\n",
    "                    aligned_bias = torch.matmul(torch.diag(1 / beta_bias), torch.matmul(transport_matrix_triplet.T, W_A_bias))\n",
    "                    aligned_bias = aligned_bias.reshape(m)\n",
    "                    W_fusion[nameA] = (aligned_bias + weightB) / 2\n",
    "                else:\n",
    "                    m = weightB.shape[0]\n",
    "                    beta_bias = torch.ones(m) * (1/m)\n",
    "                    W_A_bias = weightA.reshape(m, 1)\n",
    "                    aligned_bias = torch.matmul(torch.diag(1 / beta_bias), torch.matmul(transport_matrix.T, W_A_bias))\n",
    "                    aligned_bias = aligned_bias.reshape(m)\n",
    "                    W_fusion[nameA] = (aligned_bias + weightB) / 2\n",
    "            else:\n",
    "                W_fusion[nameA] = a * weightA + (1-a) * weightB\n",
    "        else:\n",
    "            W_fusion[nameA] = a * weightA + (1-a) * weightB\n",
    "# Assign the weights\n",
    "with torch.no_grad():\n",
    "    for name, param in fusedModel.named_parameters():\n",
    "        param.data = torch.nn.Parameter(W_fusion[name])\n",
    "# Validate the fused model\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "val_loss, val_acc, val_f1 = validation(fusedModel, valid_iter, None, criterion, device)\n",
    "scores['loss']['OT_pre'], scores['accuracy']['OT_pre'], scores['f1']['OT_pre'] = val_loss, val_acc, val_f1\n",
    "print(\"Validation Loss:     \", val_loss)\n",
    "print(\"Validation Accuracy:     \", val_acc.item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusedModel = TransformerClassifier(src_pad_idx = pad_idx,\n",
    "                              embedding = embedding,\n",
    "                              enc_voc_size = voc_size,\n",
    "                              max_len = 256,\n",
    "                              d_model = 16,\n",
    "                              ffn_hidden = 32,\n",
    "                              n_head = 1,\n",
    "                              n_layers = 2,\n",
    "                              drop_prob = 0.2,\n",
    "                              device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj(trial):\n",
    "    a = trial.suggest_float('a', 0, 1)\n",
    "    \n",
    "    # Create the fused weights matrix\n",
    "    W_fusion = dict.fromkeys(list(modelA.state_dict().keys()))\n",
    "    # Initialize the algorithm\n",
    "    m = list(modelB.state_dict().items())[1][1].shape[1]\n",
    "    beta = torch.ones(m) * (1/m)\n",
    "    transport_matrix = torch.matmul(torch.diag(beta), torch.eye(m))\n",
    "\n",
    "    # Fusion via Optimal Transport\n",
    "    for (nameA, weightA), (nameB, weightB) in zip(modelA.named_parameters(), modelB.named_parameters()):\n",
    "        if nameA == \"encoder.emb.tok_emb.embedding.weight\":\n",
    "            W_fusion[nameA] = weightA\n",
    "        else:   \n",
    "            if \"weight\" in nameA:\n",
    "                if \"encoder\" in nameA:\n",
    "                    if \"concat\" not in nameA and \"linear\" not in nameA: \n",
    "                        transport_matrix_triplet = torch.empty((weightA.shape[0], weightB.shape[0]))\n",
    "                        W_fusion[nameA], transport_matrix_triplet, _ = fusion_multihead_multilayer(nameA, nameB, weightA, weightB, transport_matrix, beta, fusedModel.n_head, 2)\n",
    "                    else:\n",
    "                        W_fusion[nameA], transport_matrix, beta = fusion(nameA, nameB, weightA, weightB, transport_matrix, beta)\n",
    "\n",
    "                else:\n",
    "                    W_fusion[nameA] = a * weightA + (1-a) * weightB\n",
    "            elif \"bias\" in nameA:\n",
    "                if \"encoder\" in nameA: \n",
    "                    if \"concat\" not in nameA and \"linear\" not in nameA: \n",
    "                        m = weightB.shape[0]\n",
    "                        beta_bias = torch.ones(m) * (1/m)\n",
    "                        W_A_bias = weightA.reshape(m, 1)\n",
    "                        aligned_bias = torch.matmul(torch.diag(1 / beta_bias), torch.matmul(transport_matrix_triplet.T, W_A_bias))\n",
    "                        aligned_bias = aligned_bias.reshape(m)\n",
    "                        W_fusion[nameA] = (aligned_bias + weightB) / 2\n",
    "                    else:\n",
    "                        m = weightB.shape[0]\n",
    "                        beta_bias = torch.ones(m) * (1/m)\n",
    "                        W_A_bias = weightA.reshape(m, 1)\n",
    "                        aligned_bias = torch.matmul(torch.diag(1 / beta_bias), torch.matmul(transport_matrix.T, W_A_bias))\n",
    "                        aligned_bias = aligned_bias.reshape(m)\n",
    "                        W_fusion[nameA] = (aligned_bias + weightB) / 2\n",
    "                else:\n",
    "                    W_fusion[nameA] = a * weightA + (1-a) * weightB\n",
    "            else:\n",
    "                W_fusion[nameA] = a * weightA + (1-a) * weightB\n",
    "\n",
    "    # Assign the weights\n",
    "    with torch.no_grad():\n",
    "        for name, param in fusedModel.named_parameters():\n",
    "            param.data = torch.nn.Parameter(W_fusion[name])\n",
    "\n",
    "    # Validate the fused model\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    val_loss, val_acc, val_f1 = validation(fusedModel, valid_iter, None, criterion, device)\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-30 15:19:39,165]\u001b[0m A new study created in memory with name: no-name-4acba308-fb73-42c5-8496-dca3631aa836\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 15:19:58,384]\u001b[0m Trial 0 finished with value: 0.854739228884379 and parameters: {'a': 0.9832036567452003}. Best is trial 0 with value: 0.854739228884379.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 15:20:16,796]\u001b[0m Trial 1 finished with value: 1.0881722768147786 and parameters: {'a': 0.1758490581392247}. Best is trial 0 with value: 0.854739228884379.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 15:20:35,644]\u001b[0m Trial 2 finished with value: 0.8684331278006235 and parameters: {'a': 0.9970797215861974}. Best is trial 0 with value: 0.854739228884379.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 15:20:53,443]\u001b[0m Trial 3 finished with value: 0.8378826479117075 and parameters: {'a': 0.9632188911445807}. Best is trial 3 with value: 0.8378826479117075.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 15:21:10,874]\u001b[0m Trial 4 finished with value: 0.7351060807704926 and parameters: {'a': 0.6722490075535558}. Best is trial 4 with value: 0.7351060807704926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 15:21:29,289]\u001b[0m Trial 5 finished with value: 0.9225539763768514 and parameters: {'a': 0.3546176005108378}. Best is trial 4 with value: 0.7351060807704926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 15:21:47,824]\u001b[0m Trial 6 finished with value: 0.9803524414698283 and parameters: {'a': 0.27988394048659215}. Best is trial 4 with value: 0.7351060807704926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 15:22:07,241]\u001b[0m Trial 7 finished with value: 1.0959977706273396 and parameters: {'a': 0.16535732138398573}. Best is trial 4 with value: 0.7351060807704926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 15:22:29,485]\u001b[0m Trial 8 finished with value: 0.9179728527863821 and parameters: {'a': 0.3523073338855297}. Best is trial 4 with value: 0.7351060807704926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 15:22:50,277]\u001b[0m Trial 9 finished with value: 0.8550724188486735 and parameters: {'a': 0.9863623831398679}. Best is trial 4 with value: 0.7351060807704926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 15:23:05,179]\u001b[0m Trial 10 finished with value: 0.7428570091724396 and parameters: {'a': 0.6487347702963226}. Best is trial 4 with value: 0.7351060807704926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 15:23:21,265]\u001b[0m Trial 11 finished with value: 0.7390149732430776 and parameters: {'a': 0.6692432457820547}. Best is trial 4 with value: 0.7351060807704926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 15:23:38,554]\u001b[0m Trial 12 finished with value: 0.7351178626219431 and parameters: {'a': 0.6662674888254271}. Best is trial 4 with value: 0.7351060807704926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 15:23:53,381]\u001b[0m Trial 13 finished with value: 0.7313193281491598 and parameters: {'a': 0.7288426842142908}. Best is trial 13 with value: 0.7313193281491598.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 15:24:08,522]\u001b[0m Trial 14 finished with value: 0.7323501805464426 and parameters: {'a': 0.764150273519483}. Best is trial 13 with value: 0.7313193281491598.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 15:24:26,977]\u001b[0m Trial 15 finished with value: 0.7447201609611511 and parameters: {'a': 0.8128056019765754}. Best is trial 13 with value: 0.7313193281491598.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 15:24:42,214]\u001b[0m Trial 16 finished with value: 0.8210108081499735 and parameters: {'a': 0.48486257509031905}. Best is trial 13 with value: 0.7313193281491598.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 15:24:58,449]\u001b[0m Trial 17 finished with value: 0.7425362964471182 and parameters: {'a': 0.8134943247419848}. Best is trial 13 with value: 0.7313193281491598.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 15:25:15,669]\u001b[0m Trial 18 finished with value: 0.7423459788163503 and parameters: {'a': 0.8022459882326257}. Best is trial 13 with value: 0.7313193281491598.\u001b[0m\n",
      "\u001b[32m[I 2022-12-30 15:25:35,784]\u001b[0m Trial 19 finished with value: 0.8218642274538676 and parameters: {'a': 0.47876380312834516}. Best is trial 13 with value: 0.7313193281491598.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(obj, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\atace\\OneDrive\\Desktop\\ETH\\9.Semester\\Deep Learning\\project\\Exploring-Model-Fusion-with-Optimal-Transport-on-Transformers\\utils.py:159: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  src, trg = torch.tensor(src).to(device), torch.tensor(trg).to(device)  # put to cpu/gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:      0.7322940131028494\n",
      "Validation Accuracy:      0.6673408417935702\n"
     ]
    }
   ],
   "source": [
    "a = study.best_params[\"a\"]\n",
    "\n",
    "# Create the fused weights matrix\n",
    "W_fusion = dict.fromkeys(list(modelA.state_dict().keys()))\n",
    "# Initialize the algorithm\n",
    "m = list(modelB.state_dict().items())[1][1].shape[1]\n",
    "beta = torch.ones(m) * (1/m)\n",
    "transport_matrix = torch.matmul(torch.diag(beta), torch.eye(m))\n",
    "# Fusion via Optimal Transport\n",
    "for (nameA, weightA), (nameB, weightB) in zip(modelA.named_parameters(), modelB.named_parameters()):\n",
    "    if nameA == \"encoder.emb.tok_emb.embedding.weight\":\n",
    "        W_fusion[nameA] = weightA\n",
    "    else:   \n",
    "        if \"weight\" in nameA:\n",
    "            if \"encoder\" in nameA:\n",
    "                if \"concat\" not in nameA and \"linear\" not in nameA: \n",
    "                    transport_matrix_triplet = torch.empty((weightA.shape[0], weightB.shape[0]))\n",
    "                    W_fusion[nameA], transport_matrix_triplet, _ = fusion_multihead_multilayer(nameA, nameB, weightA, weightB, transport_matrix, beta, fusedModel.n_head, 2)\n",
    "                else:\n",
    "                    W_fusion[nameA], transport_matrix, beta = fusion(nameA, nameB, weightA, weightB, transport_matrix, beta)\n",
    "            else:\n",
    "                W_fusion[nameA] = a * weightA + (1-a) * weightB\n",
    "        elif \"bias\" in nameA:\n",
    "            if \"encoder\" in nameA: \n",
    "                if \"concat\" not in nameA and \"linear\" not in nameA: \n",
    "                    m = weightB.shape[0]\n",
    "                    beta_bias = torch.ones(m) * (1/m)\n",
    "                    W_A_bias = weightA.reshape(m, 1)\n",
    "                    aligned_bias = torch.matmul(torch.diag(1 / beta_bias), torch.matmul(transport_matrix_triplet.T, W_A_bias))\n",
    "                    aligned_bias = aligned_bias.reshape(m)\n",
    "                    W_fusion[nameA] = (aligned_bias + weightB) / 2\n",
    "                else:\n",
    "                    m = weightB.shape[0]\n",
    "                    beta_bias = torch.ones(m) * (1/m)\n",
    "                    W_A_bias = weightA.reshape(m, 1)\n",
    "                    aligned_bias = torch.matmul(torch.diag(1 / beta_bias), torch.matmul(transport_matrix.T, W_A_bias))\n",
    "                    aligned_bias = aligned_bias.reshape(m)\n",
    "                    W_fusion[nameA] = (aligned_bias + weightB) / 2\n",
    "            else:\n",
    "                W_fusion[nameA] = a * weightA + (1-a) * weightB\n",
    "        else:\n",
    "            W_fusion[nameA] = a * weightA + (1-a) * weightB\n",
    "# Assign the weights\n",
    "with torch.no_grad():\n",
    "    for name, param in fusedModel.named_parameters():\n",
    "        param.data = torch.nn.Parameter(W_fusion[name])\n",
    "# Validate the fused model\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "val_loss, val_acc, val_f1 = validation(fusedModel, valid_iter, None, criterion, device)\n",
    "scores['loss']['OT_pre'], scores['accuracy']['OT_pre'], scores['f1']['OT_pre'] = val_loss, val_acc, val_f1\n",
    "print(\"Validation Loss:     \", val_loss)\n",
    "print(\"Validation Accuracy:     \", val_acc.item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recalibrate the normalization layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/47 [00:00<?, ?it/s]C:\\Users\\atace\\AppData\\Local\\Temp/ipykernel_2588/1843898165.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  src, trg = torch.tensor(src).to(device), torch.tensor(trg).to(device) # put to cpu/gpu\n",
      "100%|██████████| 47/47 [02:06<00:00,  2.70s/it]\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(fusedModel.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "clip = 1\n",
    "\n",
    "fusedModel.train()\n",
    "for name, param in fusedModel.named_parameters():\n",
    "    if \"weight\" in name or \"bias\" in name:\n",
    "        param.requires_grad = False\n",
    "    \n",
    "for i, batch in enumerate(tqdm(train_iter)):\n",
    "            src = batch[0] # X\n",
    "            trg = batch[1] # y\n",
    "            src, trg = torch.tensor(src).to(device), torch.tensor(trg).to(device) # put to cpu/gpu\n",
    "            optimizer.zero_grad() # reset optimizer\n",
    "            output = fusedModel(src) # predict\n",
    "            y_pred = torch.argmax(output, dim=-1) # logits -> labels\n",
    "            output_reshape = output.contiguous().view(-1, output.shape[-1])\n",
    "            trg = trg.to(torch.int64)\n",
    "            loss = criterion(output_reshape, trg) # calculate loss\n",
    "            agreements = torch.eq(y_pred, trg)\n",
    "            accuracy = torch.mean(agreements.double()) # calculate accuracy\n",
    "            loss.backward() # backward pass\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(fusedModel.parameters(), clip)\n",
    "            optimizer.step() # optimize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:      0.5179742028315862\n",
      "Validation Accuracy:      0.7538269352791879\n"
     ]
    }
   ],
   "source": [
    "# Validate the fused model\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "val_loss, val_acc, val_f1 = validation(fusedModel, valid_iter, None, criterion, device)\n",
    "scores['loss']['OT_pre'], scores['accuracy']['OT_pre'], scores['f1']['OT_pre'] = val_loss, val_acc, val_f1\n",
    "scores['loss']['OT_calibr'], scores['accuracy']['OT_calibr'], scores['f1']['OT_calibr'] = val_loss, val_acc, val_f1\n",
    "print(\"Validation Loss:     \", val_loss)\n",
    "print(\"Validation Accuracy:     \", val_acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in fusedModel.named_parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/47 [00:00<?, ?it/s]C:\\Users\\atace\\AppData\\Local\\Temp/ipykernel_2588/2985598703.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  src, trg = torch.tensor(src).to(device), torch.tensor(trg).to(device) # put to cpu/gpu\n",
      "100%|██████████| 47/47 [01:23<00:00,  1.78s/it]\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(fusedModel.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "clip = 1\n",
    "\n",
    "fusedModel.train()\n",
    "for name, param in fusedModel.named_parameters():\n",
    "    if \"encoder\" in name:\n",
    "        param.requires_grad = False\n",
    "    \n",
    "for i, batch in enumerate(tqdm(train_iter)):\n",
    "            src = batch[0] # X\n",
    "            trg = batch[1] # y\n",
    "            src, trg = torch.tensor(src).to(device), torch.tensor(trg).to(device) # put to cpu/gpu\n",
    "            optimizer.zero_grad() # reset optimizer\n",
    "            output = fusedModel(src) # predict\n",
    "            y_pred = torch.argmax(output, dim=-1) # logits -> labels\n",
    "            output_reshape = output.contiguous().view(-1, output.shape[-1])\n",
    "            trg = trg.to(torch.int64)\n",
    "            loss = criterion(output_reshape, trg) # calculate loss\n",
    "            agreements = torch.eq(y_pred, trg)\n",
    "            accuracy = torch.mean(agreements.double()) # calculate accuracy\n",
    "            loss.backward() # backward pass\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(fusedModel.parameters(), clip)\n",
    "            optimizer.step() # optimize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:      0.4185267935196559\n",
      "Validation Accuracy:      0.8062291798857868\n"
     ]
    }
   ],
   "source": [
    "# Validate the fused model\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "val_loss, val_acc, val_f1 = validation(fusedModel, valid_iter, None, criterion, device)\n",
    "scores['loss']['OT_last_layer'], scores['accuracy']['OT_last_layer'], scores['f1']['OT_last_layer'] = val_loss, val_acc, val_f1\n",
    "print(\"Validation Loss:     \", val_loss)\n",
    "print(\"Validation Accuracy:     \", val_acc.item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss Fused Model:      0.4156232972939809\n",
      "Validation Accuracy Fused Model:      0.8086926424050632\n",
      "Validation Loss Model A:      0.5493571062882742\n",
      "Validation Accuracy Model A:      0.7044064807489452\n",
      "Validation Loss Model B:      0.5096772213776907\n",
      "Validation Accuracy Model B:      0.8205556104957806\n"
     ]
    }
   ],
   "source": [
    "# Test the models\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "test_loss_fused, test_acc_fused, test_f1_fused  = validation(fusedModel, test_iter, None, criterion, device)\n",
    "scores['loss']['OT_test_set'], scores['accuracy']['OT_test_set'], scores['f1']['OT_test_set'] = test_loss_fused, test_acc_fused, test_f1_fused\n",
    "test_loss_A, test_acc_A, test_f1_A  = validation(modelA, test_iter, None, criterion, device)\n",
    "scores['loss']['A'], scores['accuracy']['A'], scores['f1']['A'] = test_loss_A, test_acc_A, test_f1_A\n",
    "test_loss_B, test_acc_B, test_f1_B  = validation(modelB, test_iter, None, criterion, device)\n",
    "scores['loss']['B'], scores['accuracy']['B'], scores['f1']['B'] = test_loss_A, test_acc_A, test_f1_A\n",
    "\n",
    "print(\"Validation Loss Fused Model:     \", test_loss_fused)\n",
    "print(\"Validation Accuracy Fused Model:     \", test_acc_fused.item())\n",
    "print(\"Validation Loss Model A:     \", test_loss_A)\n",
    "print(\"Validation Accuracy Model A:     \", test_acc_A.item())\n",
    "print(\"Validation Loss Model B:     \", test_loss_B)\n",
    "print(\"Validation Accuracy Model B:     \", test_acc_B.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A_test_set</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_test_set</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OT_pre</th>\n",
       "      <td>0.517974</td>\n",
       "      <td>tensor(0.7538, dtype=torch.float64)</td>\n",
       "      <td>tensor(0.7552)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OT_calibr</th>\n",
       "      <td>0.517974</td>\n",
       "      <td>tensor(0.7538, dtype=torch.float64)</td>\n",
       "      <td>tensor(0.7552)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OT_last_layer</th>\n",
       "      <td>0.418527</td>\n",
       "      <td>tensor(0.8062, dtype=torch.float64)</td>\n",
       "      <td>tensor(0.8057)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OT_test_set</th>\n",
       "      <td>0.415623</td>\n",
       "      <td>tensor(0.8087, dtype=torch.float64)</td>\n",
       "      <td>tensor(0.8091)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.549357</td>\n",
       "      <td>tensor(0.7044, dtype=torch.float64)</td>\n",
       "      <td>tensor(0.7042)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.549357</td>\n",
       "      <td>tensor(0.7044, dtype=torch.float64)</td>\n",
       "      <td>tensor(0.7042)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Loss                             Accuracy        F1 score\n",
       "A_test_set           []                                   []              []\n",
       "B_test_set           []                                   []              []\n",
       "OT_pre         0.517974  tensor(0.7538, dtype=torch.float64)  tensor(0.7552)\n",
       "OT_calibr      0.517974  tensor(0.7538, dtype=torch.float64)  tensor(0.7552)\n",
       "OT_last_layer  0.418527  tensor(0.8062, dtype=torch.float64)  tensor(0.8057)\n",
       "OT_test_set    0.415623  tensor(0.8087, dtype=torch.float64)  tensor(0.8091)\n",
       "A              0.549357  tensor(0.7044, dtype=torch.float64)  tensor(0.7042)\n",
       "B              0.549357  tensor(0.7044, dtype=torch.float64)  tensor(0.7042)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 8 elements, new values have 6 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2588/1663159567.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# rename rows, cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'F1 score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m df.index = ['Model A on test set', 'Model B on test set', 'Optimal transport + weighted fusion', 'OT + weighted fusion (recalibrated)',\n\u001b[0m\u001b[0;32m      4\u001b[0m             'OT + weighted fusion (last layer retrained)', 'OT + weighted fusion (last layer retrained) on test set']\n",
      "\u001b[1;32mc:\\Users\\atace\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   5586\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5587\u001b[0m             \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5588\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5589\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5590\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\atace\\anaconda3\\lib\\site-packages\\pandas\\_libs\\properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\atace\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    767\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 769\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    770\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    771\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\atace\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;31m# Caller is responsible for ensuring we have an Index object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_set_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\atace\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\base.py\u001b[0m in \u001b[0;36m_validate_set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mnew_len\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mold_len\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m     70\u001b[0m                 \u001b[1;34mf\"Length mismatch: Expected axis has {old_len} elements, new \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[1;34mf\"values have {new_len} elements\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 8 elements, new values have 6 elements"
     ]
    }
   ],
   "source": [
    "# rename rows, cols\n",
    "df.columns = ['Loss', 'Accuracy', 'F1 score']\n",
    "df.index = ['Model A on test set', 'Model B on test set', 'Optimal transport + weighted fusion', 'OT + weighted fusion (recalibrated)',\n",
    "            'OT + weighted fusion (last layer retrained)', 'OT + weighted fusion (last layer retrained) on test set']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boldify highest score\n",
    "for col in (0, 1, 2):\n",
    "    if col == 0:\n",
    "        index_max = np.argmin([float(entry.split('±')[0]) for entry in df.iloc[:, col]])\n",
    "    else:\n",
    "        index_max = np.argmax([float(entry.split('±')[0]) for entry in df.iloc[:, col]])\n",
    "    entry = df.iloc[index_max, col]\n",
    "    entry = 'BOLD{' + entry + '}'\n",
    "    df.iloc[index_max, col] = entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to latex\n",
    "latex = df.to_latex(index=True,\n",
    "                    bold_rows=True,\n",
    "                    caption='Model performance (5-fold CV)',\n",
    "                    position='H').replace('BOLD\\\\', r'\\textbf').replace('\\}', '}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(latex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1744cd9dc0832a8d503a2c77e6bee76d4493b3bf33a738cf38afd0bb2e60262"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

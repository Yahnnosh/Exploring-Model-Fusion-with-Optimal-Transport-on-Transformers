{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAlOQ-4EbsYR",
        "outputId": "aa3fab9d-d794-4261-ff25-f271e151d150"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting captum\n",
            "  Downloading captum-0.6.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6 in /usr/local/lib/python3.8/dist-packages (from captum) (1.13.0+cu116)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from captum) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from captum) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.6->captum) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->captum) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->captum) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->captum) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->captum) (1.4.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->captum) (1.15.0)\n",
            "Installing collected packages: captum\n",
            "Successfully installed captum-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install captum"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "idk5BQDjeIfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "\n",
        "from transformer import TransformerClassifier\n",
        "from dataloader import *\n",
        "import torch\n",
        "import ot\n",
        "from copy import deepcopy\n",
        "from tqdm import tqdm\n",
        "import optuna\n",
        "\n",
        "from captum.attr import (\n",
        "    GradientShap,\n",
        "    DeepLift,\n",
        "    DeepLiftShap,\n",
        "    IntegratedGradients,\n",
        "    LayerConductance,\n",
        "    NeuronConductance,\n",
        "    NoiseTunnel,\n",
        ")\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "SNlxMzUxcX4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Data"
      ],
      "metadata": {
        "id": "PC7VAf2Md6jH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#init\n",
        "tokenizer = Tokenizer()\n",
        "loader = DataLoader(tokenize = tokenizer.tokenize)\n",
        "\n",
        "# import data (combine train/test as we split afterwards anyways)\n",
        "data = pd.read_csv(\"./Data/IMDB Dataset.csv\", encoding='ISO-8859-1')\n",
        "# convert string label to binary (int) label (spam:1, non-spam:0)\n",
        "data[\"sentiment\"] = data['sentiment'].apply(lambda x : int(x == \"positive\"))\n",
        "\n",
        "# train, test, val split\n",
        "train, valid, test = loader.make_dataset(data)\n",
        "vocab = loader.get_vocab(train.iloc[:, 0])\n",
        "train_iter, valid_iter, test_iter = loader.make_iter(train, valid, test,\n",
        "                                                     batch_size=512,\n",
        "                                                     device=device)\n",
        "\n",
        "# NLP stuff\n",
        "pad_idx = vocab['__PAD__']\n",
        "voc_size = len(vocab)\n",
        "print(\"Vocabulary Size : \", voc_size)"
      ],
      "metadata": {
        "id": "4B4M7FYTeAPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validation(model, iterator, criterion, device):\n",
        "    # set model into evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # validation\n",
        "    # loss, metrics for current epoch\n",
        "    val_epoch_loss = 0\n",
        "    val_epoch_accuracy = 0\n",
        "\n",
        "    with torch.no_grad(): # stop graph\n",
        "        # batches\n",
        "        for i, batch in enumerate(iterator):\n",
        "            src = batch[0] # X\n",
        "            trg = batch[1] # y\n",
        "            src, trg = torch.tensor(src).to(device), torch.tensor(trg).to(device) # put to cpu/gpu\n",
        "            output = model(src)\n",
        "            y_pred = torch.argmax(output, dim=-1) # logits -> labels\n",
        "            output_reshape = output.contiguous().view(-1, output.shape[-1])\n",
        "            trg = trg.to(torch.int64)\n",
        "\n",
        "            loss = criterion(output_reshape, trg) # calculate loss\n",
        "            agreements = torch.eq(y_pred, trg)\n",
        "            accuracy = torch.mean(agreements.double()) # calculate accuracy\n",
        "\n",
        "            val_epoch_loss += loss.item()\n",
        "            val_epoch_accuracy += accuracy\n",
        "\n",
        "    # return mean loss w.r.t. batches\n",
        "    return val_epoch_loss / len(iterator), val_epoch_accuracy / len(iterator)"
      ],
      "metadata": {
        "id": "GvzhZ1aZeLQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the embedding matrix\n",
        "embedding = torch.load(\"Models/embedding_16.pt\")"
      ],
      "metadata": {
        "id": "ZQ3689E8eLEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Model Weights"
      ],
      "metadata": {
        "id": "Na9ij-mbeUmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelA = TransformerClassifier(src_pad_idx = pad_idx,\n",
        "                              embedding=embedding,\n",
        "                              enc_voc_size = voc_size,\n",
        "                              max_len = 256,\n",
        "                              d_model = 16,\n",
        "                              ffn_hidden = 32,\n",
        "                              n_head = 1,\n",
        "                              n_layers = 1,\n",
        "                              drop_prob = 0.5,\n",
        "                              device = device)\n",
        "\n",
        "modelA.load_state_dict(torch.load(\"Models\\modelA_IMDB_256\"))\n",
        "modelA.eval()"
      ],
      "metadata": {
        "id": "2dvWPFbMeVDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelB = TransformerClassifier(src_pad_idx = pad_idx,\n",
        "                              embedding=embedding,\n",
        "                              enc_voc_size = voc_size,\n",
        "                              max_len = 256,\n",
        "                              d_model = 16,\n",
        "                              ffn_hidden = 32,\n",
        "                              n_head = 1,\n",
        "                              n_layers = 1,\n",
        "                              drop_prob = 0.5,\n",
        "                              device = device)\n",
        "\n",
        "modelB.load_state_dict(torch.load(\"Models\\modelB_IMBD_256\"))\n",
        "modelB.eval()"
      ],
      "metadata": {
        "id": "W3-O_CKieZ6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in modelA.named_parameters():\n",
        "    print(name, param.shape)"
      ],
      "metadata": {
        "id": "r3n2-2Feehoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OT Functions"
      ],
      "metadata": {
        "id": "i42cZituekzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getSupport(model, trainloader, l, alignment = \"acts\", numOfBatches= 10):\n",
        "    '''\n",
        "    Get the support matrices using Activation-based (\"acts\") or Weight-based (\"wts\") alignment \n",
        "    '''\n",
        "    if alignment == \"acts\":\n",
        "        activation = None\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            if i >= numOfBatches:\n",
        "                break\n",
        "            \n",
        "            inputs, targets = data\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            if activation is None:\n",
        "                activation = model.actMatrix[l]\n",
        "            else:\n",
        "                activation = torch.cat((activation, model.actMatrix[l]))\n",
        "\n",
        "        return activation\n",
        "    elif alignment == \"wts\":\n",
        "        return model.state_dict()[l]"
      ],
      "metadata": {
        "id": "RRM_RSnjelNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fusion(nameA, nameB, weightA, weightB, transport_matrix, beta):\n",
        "    support_y = getSupport(modelB, train_iter, nameB, alignment=\"wts\")\n",
        "    # Get the weights at layer \"idx\" from the first model\n",
        "    W_A = weightA\n",
        "    W_B = weightB\n",
        "    # Align the weights from the first model\n",
        "    aligned_W = torch.matmul(W_A, torch.matmul(transport_matrix, torch.diag(1 / beta)))\n",
        "    # Get the X-Support\n",
        "    n = W_A.shape[0]\n",
        "    alpha = torch.ones(n) * (1/n)\n",
        "    support_x = getSupport(modelA, train_iter, nameA, alignment=\"wts\")\n",
        "    # Calculate the euclidean distance between the supports\n",
        "    distance = ot.dist(support_x, support_y)\n",
        "    # Calculate beta\n",
        "    m = W_B.shape[0]\n",
        "    beta = torch.ones(m) * (1/m)\n",
        "    # Calculate the transport matrix using optimal transport\n",
        "    transport_matrix = torch.from_numpy(ot.emd(alpha.numpy(), beta.numpy(), distance.detach().numpy())).float().reshape((n, m))\n",
        "    # Align model neurons\n",
        "    aligned_model = torch.matmul(torch.diag(1 / beta), torch.matmul(transport_matrix.T, aligned_W))\n",
        "    # Get the weights at layer \"idx\" from the second model\n",
        "    fused = (aligned_model + W_B) / 2 \n",
        "    return  fused, transport_matrix, beta"
      ],
      "metadata": {
        "id": "aQc-dj4-evQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neuron Importance (under dev)"
      ],
      "metadata": {
        "id": "bkbwNsFG8wt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ig = IntegratedGradients(model)\n",
        "attributions, delta = ig.attribute(input, baseline, target=0, return_convergence_delta=True)\n",
        "print('IG Attributions:', attributions)\n",
        "print('Convergence Delta:', delta)"
      ],
      "metadata": {
        "id": "3lx-116D803Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fusion via Optimal Transport"
      ],
      "metadata": {
        "id": "SByWXq2Me55d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fusedModel = TransformerClassifier(src_pad_idx = pad_idx,\n",
        "                              embedding = embedding,\n",
        "                              enc_voc_size = voc_size,\n",
        "                              max_len = 256,\n",
        "                              d_model = 16,\n",
        "                              ffn_hidden = 32,\n",
        "                              n_head = 1,\n",
        "                              n_layers = 1,\n",
        "                              drop_prob = 0.2,\n",
        "                              device = device)\n",
        "\n",
        "#fusedModel.eval()"
      ],
      "metadata": {
        "id": "qjEWvxIee-tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Different Support Mass Distributions\n",
        "\n",
        "### Betas and alphas in the below cell should be set to the output of one of these methods\n",
        "\n",
        "## The default distribution we normally use is uniform dist\n",
        "def random_mass(n_support: int):\n",
        "    '''\n",
        "    Input\n",
        "        n_support (int): number of supports\n",
        "    '''\n",
        "    action_logits = torch.rand(n_support)\n",
        "    action_probs = nn.functional.softmax(action_logits, dim=-1)\n",
        "    return action_probs\n",
        "\n",
        "def gaussian_mass(n_support: int):\n",
        "    '''\n",
        "    Normal distribution with mean 0 and std 1\n",
        "    Input\n",
        "        n_support (int): number of supports\n",
        "    '''\n",
        "    action_logits = torch.empty(n_support)\n",
        "    action_probs = nn.functional.softmax(action_logits.normal_(), dim=-1)\n",
        "    return action_probs\n",
        "\n",
        "def geometric_mass(n_support: int):\n",
        "    '''\n",
        "    Geometric distribution with success probability 0.5\n",
        "    Input\n",
        "        n_support (int): number of supports\n",
        "    '''\n",
        "    action_logits = torch.empty(n_support)\n",
        "    action_probs = nn.functional.softmax(action_logits.geometric_(0.5), dim=-1)\n",
        "    return action_probs"
      ],
      "metadata": {
        "id": "cuhVNVTScvvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change 10th line in the code cell below (in obj(trial) method) and 9th line in 3 cells below (the run with the best parameters)"
      ],
      "metadata": {
        "id": "Crv2sLw4_T5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def obj(trial):\n",
        "    a = trial.suggest_float('a', 0, 1)\n",
        "    \n",
        "    # Create the fused weights matrix\n",
        "    W_fusion = dict.fromkeys(list(modelA.state_dict().keys()))\n",
        "    # Initialize the algorithm\n",
        "    m = list(modelB.state_dict().items())[1][1].shape[1]\n",
        "    \n",
        "    ## Set mass_dist to one of the methods in 'Different Support Mass Distributions' and run the trial\n",
        "    mass_dist = random_mass(m)\n",
        "    \n",
        "    beta = mass_dist\n",
        "    transport_matrix = torch.matmul(torch.diag(beta), torch.eye(m))\n",
        "\n",
        "    # Fusion via Optimal Transport\n",
        "    for (nameA, weightA), (nameB, weightB) in zip(modelA.named_parameters(), modelB.named_parameters()):\n",
        "        if nameA == \"encoder.emb.tok_emb.embedding.weight\":\n",
        "            W_fusion[nameA] = weightA\n",
        "        else:\n",
        "            if \"weight\" in nameA:\n",
        "                if \"encoder\" in nameA:\n",
        "                    if \"concat\" not in nameA and \"linear\" not in nameA: \n",
        "                        W_fusion[nameA], transport_matrix_triplet, _ = fusion(nameA, nameB, weightA, weightB, transport_matrix, beta)\n",
        "                    else:\n",
        "                        W_fusion[nameA], transport_matrix, beta = fusion(nameA, nameB, weightA, weightB, transport_matrix, beta)\n",
        "\n",
        "                else:\n",
        "                    W_fusion[nameA] = a * weightA + (1-a) * weightB\n",
        "            elif \"bias\" in nameA:\n",
        "                if \"encoder\" in nameA: \n",
        "                    if \"concat\" not in nameA and \"linear\" not in nameA: \n",
        "                        m = weightB.shape[0]\n",
        "                        beta_bias = torch.ones(m) * (1/m)\n",
        "                        W_A_bias = weightA.reshape(m, 1)\n",
        "                        aligned_bias = torch.matmul(torch.diag(1 / beta_bias), torch.matmul(transport_matrix_triplet.T, W_A_bias))\n",
        "                        aligned_bias = aligned_bias.reshape(m)\n",
        "                        W_fusion[nameA] = (aligned_bias + weightB) / 2\n",
        "                    else:\n",
        "                        m = weightB.shape[0]\n",
        "                        beta_bias = torch.ones(m) * (1/m)\n",
        "                        W_A_bias = weightA.reshape(m, 1)\n",
        "                        aligned_bias = torch.matmul(torch.diag(1 / beta_bias), torch.matmul(transport_matrix.T, W_A_bias))\n",
        "                        aligned_bias = aligned_bias.reshape(m)\n",
        "                        W_fusion[nameA] = (aligned_bias + weightB) / 2\n",
        "                else:\n",
        "                    W_fusion[nameA] = a * weightA + (1-a) * weightB\n",
        "            else:\n",
        "                W_fusion[nameA] = a * weightA + (1-a) * weightB\n",
        "\n",
        "    # Assign the weights\n",
        "    with torch.no_grad():\n",
        "        for name, param in fusedModel.named_parameters():\n",
        "            param.data = torch.nn.Parameter(W_fusion[name])\n",
        "\n",
        "    # Validate the fused model\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    val_loss, val_acc = validation(fusedModel, valid_iter, criterion, device)\n",
        "    return val_loss"
      ],
      "metadata": {
        "id": "lRaXuS4BfHDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study()\n",
        "study.optimize(obj, n_trials=20)"
      ],
      "metadata": {
        "id": "abppdLl3fPEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = study.best_params[\"a\"]\n",
        "\n",
        "# Create the fused weights matrix\n",
        "W_fusion = dict.fromkeys(list(modelA.state_dict().keys()))\n",
        "# Initialize the algorithm\n",
        "m = list(modelB.state_dict().items())[1][1].shape[1]\n",
        "\n",
        "## Set mass_dist to the same method used in the trial\n",
        "mass_dist = random_mass(m)\n",
        "beta = mass_dist\n",
        "\n",
        "transport_matrix = torch.matmul(torch.diag(beta), torch.eye(m))\n",
        "# Fusion via Optimal Transport\n",
        "for (nameA, weightA), (nameB, weightB) in zip(modelA.named_parameters(), modelB.named_parameters()):\n",
        "    if nameA == \"encoder.emb.tok_emb.embedding.weight\":\n",
        "        W_fusion[nameA] = weightA\n",
        "    else:\n",
        "        if \"weight\" in nameA:\n",
        "            if \"encoder\" in nameA:\n",
        "                if \"concat\" not in nameA and \"linear\" not in nameA: \n",
        "                    W_fusion[nameA], transport_matrix_triplet, _ = fusion(nameA, nameB, weightA, weightB, transport_matrix, beta)\n",
        "                else:\n",
        "                    W_fusion[nameA], transport_matrix, beta = fusion(nameA, nameB, weightA, weightB, transport_matrix, beta)\n",
        "            else:\n",
        "                W_fusion[nameA] = a * weightA + (1-a) * weightB\n",
        "        elif \"bias\" in nameA:\n",
        "            if \"encoder\" in nameA: \n",
        "                if \"concat\" not in nameA and \"linear\" not in nameA: \n",
        "                    m = weightB.shape[0]\n",
        "                    beta_bias = torch.ones(m) * (1/m)\n",
        "                    W_A_bias = weightA.reshape(m, 1)\n",
        "                    aligned_bias = torch.matmul(torch.diag(1 / beta_bias), torch.matmul(transport_matrix_triplet.T, W_A_bias))\n",
        "                    aligned_bias = aligned_bias.reshape(m)\n",
        "                    W_fusion[nameA] = (aligned_bias + weightB) / 2\n",
        "                else:\n",
        "                    m = weightB.shape[0]\n",
        "                    beta_bias = torch.ones(m) * (1/m)\n",
        "                    W_A_bias = weightA.reshape(m, 1)\n",
        "                    aligned_bias = torch.matmul(torch.diag(1 / beta_bias), torch.matmul(transport_matrix.T, W_A_bias))\n",
        "                    aligned_bias = aligned_bias.reshape(m)\n",
        "                    W_fusion[nameA] = (aligned_bias + weightB) / 2\n",
        "            else:\n",
        "                W_fusion[nameA] = a * weightA + (1-a) * weightB\n",
        "        else:\n",
        "            W_fusion[nameA] = a * weightA + (1-a) * weightB\n",
        "                \n",
        "# Assign the weights\n",
        "with torch.no_grad():\n",
        "    for name, param in fusedModel.named_parameters():\n",
        "        param.data = torch.nn.Parameter(W_fusion[name])\n",
        "# Validate the fused model\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "val_loss, val_acc = validation(fusedModel, valid_iter, criterion, device)\n",
        "print(\"Validation Loss:     \", val_loss)\n",
        "print(\"Validation Accuracy:     \", val_acc.item())"
      ],
      "metadata": {
        "id": "vwqUqqtcfaZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recalibrate the normalization layers"
      ],
      "metadata": {
        "id": "lK5lVfsTfgM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(fusedModel.parameters(), lr=0.01)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "clip = 1\n",
        "\n",
        "fusedModel.train()\n",
        "for name, param in fusedModel.named_parameters():\n",
        "    if \"weight\" in name or \"bias\" in name:\n",
        "        param.requires_grad = False\n",
        "    \n",
        "for i, batch in enumerate(tqdm(train_iter)):\n",
        "            src = batch[0] # X\n",
        "            trg = batch[1] # y\n",
        "            src, trg = torch.tensor(src).to(device), torch.tensor(trg).to(device) # put to cpu/gpu\n",
        "            optimizer.zero_grad() # reset optimizer\n",
        "            output = fusedModel(src) # predict\n",
        "            y_pred = torch.argmax(output, dim=-1) # logits -> labels\n",
        "            output_reshape = output.contiguous().view(-1, output.shape[-1])\n",
        "            trg = trg.to(torch.int64)\n",
        "            loss = criterion(output_reshape, trg) # calculate loss\n",
        "            agreements = torch.eq(y_pred, trg)\n",
        "            accuracy = torch.mean(agreements.double()) # calculate accuracy\n",
        "            loss.backward() # backward pass\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(fusedModel.parameters(), clip)\n",
        "            optimizer.step() # optimize model"
      ],
      "metadata": {
        "id": "IfZT46dBfg_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate the fused model\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "val_loss, val_acc = validation(fusedModel, valid_iter, criterion, device)\n",
        "print(\"Validation Loss:     \", val_loss)\n",
        "print(\"Validation Accuracy:     \", val_acc.item())"
      ],
      "metadata": {
        "id": "Vq5yqLUTflPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in fusedModel.named_parameters():\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "id": "Yq2_VFCKfo98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the last layer"
      ],
      "metadata": {
        "id": "Zm5JbHEFftYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(fusedModel.parameters(), lr=0.001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "clip = 1\n",
        "\n",
        "fusedModel.train()\n",
        "for name, param in fusedModel.named_parameters():\n",
        "    if \"encoder\" in name:\n",
        "        param.requires_grad = False\n",
        "    \n",
        "for i, batch in enumerate(tqdm(train_iter)):\n",
        "            src = batch[0] # X\n",
        "            trg = batch[1] # y\n",
        "            src, trg = torch.tensor(src).to(device), torch.tensor(trg).to(device) # put to cpu/gpu\n",
        "            optimizer.zero_grad() # reset optimizer\n",
        "            output = fusedModel(src) # predict\n",
        "            y_pred = torch.argmax(output, dim=-1) # logits -> labels\n",
        "            output_reshape = output.contiguous().view(-1, output.shape[-1])\n",
        "            trg = trg.to(torch.int64)\n",
        "            loss = criterion(output_reshape, trg) # calculate loss\n",
        "            agreements = torch.eq(y_pred, trg)\n",
        "            accuracy = torch.mean(agreements.double()) # calculate accuracy\n",
        "            loss.backward() # backward pass\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(fusedModel.parameters(), clip)\n",
        "            optimizer.step() # optimize model"
      ],
      "metadata": {
        "id": "--0EelaFfwip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate the fused model\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "val_loss, val_acc = validation(fusedModel, valid_iter, criterion, device)\n",
        "print(\"Validation Loss:     \", val_loss)\n",
        "print(\"Validation Accuracy:     \", val_acc.item())"
      ],
      "metadata": {
        "id": "9NTlDIbdf4an"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Set"
      ],
      "metadata": {
        "id": "vWJBPZblgBdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the models\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "test_loss_fused, test_acc_fused = validation(fusedModel, test_iter, criterion, device)\n",
        "test_loss_A, test_acc_A = validation(modelA, test_iter, criterion, device)\n",
        "test_loss_B, test_acc_B = validation(modelB, test_iter, criterion, device)\n",
        "\n",
        "print(\"Validation Loss Fused Model:     \", test_loss_fused)\n",
        "print(\"Validation Accuracy Fused Model:     \", test_acc_fused.item())\n",
        "print(\"Validation Loss Model A:     \", test_loss_A)\n",
        "print(\"Validation Accuracy Model A:     \", test_acc_A.item())\n",
        "print(\"Validation Loss Model B:     \", test_loss_B)\n",
        "print(\"Validation Accuracy Model B:     \", test_acc_B.item())"
      ],
      "metadata": {
        "id": "EHTguHaMf7nQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}